---
title: An Operating System Level Data Migration Scheme in Hybrid DRAM-NVM Memory Architecture
date: 2023-05-12 
permalink: /pages/2476ae/
---

1. CLOCK-DWF: A Write-History-Aware Page Replacement Algorithm for Hybrid PCM and DRAM Memory Architectures
2. An Operating System Level Data Migration Scheme in Hybrid DRAM-NVM Memory Architecture

---
#### 1. CLOCK-DWF: A Write-History-Aware Page Replacement Algorithm for Hybrid PCM and DRAM Memory Architectures
**LRU**:
Even though it requires only constant time and space overhead, LRU has a critical weakness in virtual memory environments. On every memory hit, LRU needs to move a page to the most recently used (MRU) position in the list. This involves list manipulations that cannot be handled by the paging unit hardware.
**CLOCK**: 
Specifically, on a hit to a page, the paging unit hardware sets the reference bit of the page to 1 when a read or a write reference for that page occurs, and sets the dirty bit to 1 when a write reference occurs. Then, pages are maintained in a circular list.
In the course of the scan, for every page with reference bit 1, CLOCK clears it to zero, without removing the page from the list.

The reference bit of each page is an indication of whether that page has recently been accessed or not; and pages not referenced upon the return of the clock-hand to that page will be replaced. Even though CLOCK does not replace the least recently used page, it replaces a page that has not been referenced recently, that is, through the cycle of the circular list, so that temporal locality is exploited to some extent.

LRU maintains the temporal locality. 
Frequency of Write Reference collect statistics of reference cnter.

![image](https://github.com/hitqshao/qishao-notes/assets/23403286/bb52315d-df24-4598-84e9-2d7b05db5683)

![image](https://github.com/hitqshao/qishao-notes/assets/23403286/3743af17-f2fa-46d2-b527-54aedf9ff09a)

The shape of the curves in these figures can be modeled as a monotonic decreasing function, implying that a more recently referenced page is more likely to be written in the near future.

Specifically, we can observe ranking inversion of temporal locality, i.e., a more recently used page shows a smaller fraction of writes for some ranking ranges.

![image](https://github.com/hitqshao/qishao-notes/assets/23403286/a3859015-7e6c-4064-a3b8-30091626880f)

In Fig. 3, x axis is the ranking by LRU.
y axis represents the number of write references of the page ranking in x-axis.

In Fig. 4, the x-axis represents the ranking of pages based on their past write counts (black plot) and read/write counts (gray plot).
The y-axis represents the number of writes occurring on that ranking.

The reference bit of each page is an indication of whether that page has recently been accessed or not; and pages not referenced upon the return of the clock-hand to that page will be replaced. Even though CLOCK does not replace the least recently used page, it replaces a page that has not been referenced recently, that is, through the cycle of the circular list, so that temporal locality is exploited to some extent.

This indicates that frequency based estimations are more accurate compared to temporal locality based estimations for most cases. Specifically, frequency based stimations indicate that a wide range of top ranking pages, that is, pages that have been written to frequently in the past, are likely to be written to again in the future.

In summary, write frequency is generally a better estimator than temporal locality in predicting the re-reference likelihood of write references, but the very recent past write history is also a strong indicator of future writes.

**Me**
In pic4, the axis x is also ranked by number of reference. That's why its x axis can correlates with y axis.
Maybe 80% rule can also explain this.

---
#### 2. An Operating System Level Data Migration Scheme in Hybrid DRAM-NVM Memory Architecture
![image](https://github.com/hitqshao/qishao-notes/assets/23403286/83bec501-7aa0-4c08-a8dc-5cdb375ef834)

Contrary to CLOCK-DWF that places page faults issued by read requests on NVM, the proposed scheme moves all pages from disk to DRAM area. This is motivated by the fact that moving to either NVM or DRAM will result in a page write in NVM since the DRAM is always full and moving a data page to DRAM will issue an eviction to NVM. Therefore, the cost of moving to NVM or DRAM is the same in terms of writes in NVM. The newly accessed data pages have higher probability of access compared to the older data pages and moving this new page to DRAM will result in increase in DRAM hit ratio instead of NVM hit ratio.

First,it requires an ordering scheme in order to identify data pages that are cold but will be accessed once in a long time. These data pages will reside long enough in NVM to have a high counter values and therefore will be moved to DRAM where they cannot compete with hot data pages and will return to NVM which makes their migration to DRAM without any benefits. Second, there is no difference between pages that are frequently accessed and typically reside near the head of the NVM LRU queue for the entire time and data pages which go back and forth in the queue.

The housekeeping information will be only stored for a few percentage of top positions in the NVM LRU queue. Once a data page moves to the end of this selected percentage of LRU, the corresponding counter will be reset to zero. This will handle both ordering scheme and identifying burst data accesses.

Finding the data page in DRAM will result in a normal LRU housekeeping. Otherwise, the extra housekeeping information in NVM will be updated based on the request type. The read and write counters will be stored for readperc and writeperc top data pages in the NVM, respectively. 
[Still confused why they have readperc and writeperc]

The values of read threshold and write threshold determine how aggressive we plan to prevent the migrations with low probability of being useful.
![image](https://github.com/hitqshao/qishao-notes/assets/23403286/1e29cb59-437f-4499-adf9-c43d1388bc43)

To this end, we use two Least Recently Used (LRU) queues (one for DRAM and one for NVM) and optimize the LRU queue for NVM to prevent nonbeneficial migrations to DRAM.
