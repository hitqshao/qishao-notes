---
title: HBM_Paper_List
date: 2023-05-08 
permalink: /pages/24769e/
---

1. Baryon: Efficient Hybrid Memory Management with Compression and Sub-Blocking
2. CAMEO:A Two-Level Memory Organization with Capacity of Main Memory and Flexibility of Hardware-Managed Cache
3. Hybrid2: Combining Caching and Migration in Hybrid Memory Systems
4. SILC-FM: Subblocked InterLeaved Cache-Like Flat Memory Organization
5. MemPod: A Clustered Architecture for Efficient and Scalable Migration in Flat Address Space Multi-level Memories
6. Transparent Hardware Management of Stacked DRAM as Part of Memory
7. CHAMELEON: A Dynamically Reconfigurable Heterogeneous Memory System
8. BATMAN: Techniques for Maximizing System Bandwidth of Memory Systems with Stacked-DRAM
9. Heterogeneous Memory Architectures: A HW/SW Approach for Mixing Die-stacked and Off-package Memories
10. Challenges in Heterogeneous Die-Stacked and Off-Chip Memory Systems
11. Banshee: Bandwidth-Efficient DRAM Caching Via Software/Hardware Cooperation
12. Die-Stacked DRAM: Memory, Cache, or MemCache?

---
#### 2. CAMEO:A Two-Level Memory Organization with Capacity of Main Memory and Flexibility of Hardware-Managed Cache
##### MemPod:

CAMEO [13] proposes a cache-like flat address space memory management scheme in an attempt to close the gap between cache and flat memory organizations. CAMEO operates similarly to THM, however it does so at the granularity of cache lines (64B). Migrations are restricted within segments with one fast line location per segment. Its bookkeeping structures are entirely stored in memory, while a “Line Location Predictor” attempts to save some bookkeeping-related accesses by predicting the location of a line. 

CAMEO initiates a line migration upon every access to slow memory.

CAMEO can incur high migration traffic as every access could induce a migration.

---
#### 5. MemPod: A Clustered Architecture for Efficient and Scalable Migration in Flat Address Space Multi-level Memories

MemPod uses MEA counters to track page access activity and identify hot pages. They are dramatically smaller than prior tracking mechanisms while capturing activity counts and temporal recency in a way that provides more effective prediction of future page access.

What makes MEA most useful, though, is its failure mode – when it fails to find the most-accessed pages, it does so by favoring recency over quantity. That is, a page accessed several times near the end of an interval can easily knock out a page accessed many more times early in the interval. As a result, it combines both access counting and temporal locality, at a fraction of the cost of access counting alone.

![image](https://user-images.githubusercontent.com/23403286/237034027-921f15ba-0cf5-4a55-9221-deffea837202.png)

Three triggers are most commonly used whenever state must be updated based on tracking information (MC scheduling, migrations, dynamic voltage and frequency scaling etc.). Interval-based (or epoch-based) triggers occur with a set frequency, while threshold-based solutions trigger whenever a predetermined criterion is met. Finally, event-based triggers react to predefined events. Both interval-based and threshold-based approaches face the same challenge of identifying the optimal interval or threshold value.

MemPod achieves the best performance (lower AMMAT) with 50us intervals and 64 counters per Pod. MemPod’s lightweight operation allows for such small intervals. For comparison purposes, HMA [14] identi-
fied the best epoch length to be 100ms (2000x larger) in order to support all the lengthy processes that take place during a migration event for that method.

Based on these results, we use 64 MEA 2-bit counters over 50us intervals for subsequent results in this paper. Each one of the 64 MEA entries needs 21 bits for addressing the 1.1M pages per Pod and 2 bits for its counter, leading to an area cost of only 184B per Pod and 736B total. Compared to the state of the art, MemPod’s activity tracking requirement is ∼712x smaller than THM’s (512KB) and ∼12800x smaller than HMA’s (9MB).

![image](https://user-images.githubusercontent.com/23403286/237031049-f4cbb08e-5ee3-4ab5-9ffd-d4abc43306db.png)

---
#### 6. Transparent Hardware Management of Stacked DRAM as Part of Memory
##### MemPod:
Sim, et al. proposed a technique for transparent hardware management of a hybrid memory system [17],which we will refer to as “THM”. THM does not require OS intervention while managing migrations. In order to keep bookkeeping costs manageable, THM allows migrations only within sets of pages (called segments). Each segment includes one fast memory page and a set of slow memory pages. The slow pages of each segment can only migrate to the one fast page location, and any such migration results in the eviction of the currently-residing page. THM monitors memory accesses with one “competing counter” per segment resulting in a low cost profiling solution. Finally, THM supports caching part of its structures on chip while the rest is stored in memory.

THM’s competing counters can lead to false positives, allowing a cold page to migrate to fast memory.

THM offers significantly limited flexibility by restricting migrations withing segments, however this decision reduces bookkeeping costs significantly. Competing counters in each segment are used for activity tracking, occasionally leading to false (threshold-based) migration triggering if a cold page gets accessed at the right time. Identifying migration candidates incurs very little overhead since there is exactly one fast memory location for each slow memory page that triggers migration.

---
#### 9. Heterogeneous Memory Architectures: A HW/SW Approach for Mixing Die-stacked and Off-package Memories
##### MemPod:
HMA [14] is a HW/SW mechanism that attempts to predict frequently accessed pages in memory and, at predefined intervals, migrate those pages to fast memory. HW support is required for profiling memory accesses using counters for each memory page, while the migration is handled by the OS. Due to the costly OS involvement, HMA’s intervals are kept large. Additionally, the hardware cost of its profiling counters is high. However, HMA is capable of managing migrations in a flat address space without the need of additional bookkeeping for finding migrated pages as the OS can update page tables and TLBs to reflect migrations.

HMA does not require a remap table due to the OS updating the existing system’s structures. For activity tracking it uses Full Counters. The costly OS involvement and the high penalty for sorting all its
counters force HMA to operate at very large intervals, weakening its adaptability to phase changes. However, HMA offers full flexibility for migrations.
