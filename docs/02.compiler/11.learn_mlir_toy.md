---
title: MLIR TOY Tutorial
date: 2024-12-10
permalink: /pages/000011/
---

### Chapter 1. Toy Language and AST
Lexer and recursive descent parser construt AST

### Chapter 2. Emit Basic MLIR

Operations: instructions, globals(functions), modules, in LLVM

![image](https://github.com/user-attachments/assets/1547200e-1e13-4075-b202-77be37cf0b74)
From [link](https://medium.com/sniper-ai/mlir-tutorial-create-your-custom-dialect-lowering-to-llvm-ir-dialect-system-1-1f125a6a3008)

Transpose Operation

```
%t_tensor = "toy.transpose"(%tensor) {inplace = true} : (tensor<2x3xf64>) ->
tensor<3x2xf64> loc("example/file/path":12:1)
```

meaning of each part

```
result  = name of operation (input operands) dictionary of traits :
type of operations (input and output), location
```

- A name for the operation.
- A list of SSA operand values.
- A list of attributes.
- A list of types for result values.
- A source location for debugging purposes.
- A list of successors blocks (for branches, mostly).
- A list of regions (for structural operations like functions).

**Opaque API**


**Define a Toy Dialect**

dialect could be defined by c++ or tablegen(declarative specification).

after the definiation, it could be loaded to MLIR Context.
context.loadDialect<ToyDialect>();

**Defining Toy Operations**

```
class ConstantOp : public mlir::Op<
                     /// `mlir::Op` is a CRTP class, meaning that we provide the
                     /// derived class as a template parameter.
                     ConstantOp,
                     /// The ConstantOp takes zero input operands.
                     mlir::OpTrait::ZeroOperands,
                     /// The ConstantOp returns a single result.
                     mlir::OpTrait::OneResult,
                     /// We also provide a utility `getType` accessor that
                     /// returns the TensorType of the single result.
                     mlir::OpTraits::OneTypedResult<TensorType>::Impl> {

 public:
  /// Inherit the constructors from the base Op class.
  using Op::Op;
  ...
  static void build(mlir::OpBuilder &builder, mlir::OperationState &state,
                    mlir::Type result, mlir::DenseElementsAttr value);
```

register operation:

```
void ToyDialect::initialize() {
  addOperations<ConstantOp>();
}
```

**Op vs Operation: Using MLIR Operations**

**Using Operation Definition Specification Framwork**

base Toy_Op

```
class Toy_Op<string mnemonic, list<Trait> traits = []> :
    Op<Toy_Dialect, mnemonic, traits>;
```

ConstantOp

```
def ConstantOp : Toy_Op<"constant"> {
}
```

**Attaching build Methods**

In ConstantOp, it declared a list of build. ODS will generate the first build.\
As to other builds, we have to atttach.
```
def ConstantOp : Toy_Op<"constant"> {
  ...

  // Add custom build methods for the constant operation. These methods populate
  // the `state` that MLIR uses to create operations, i.e. these are used when
  // using `builder.create<ConstantOp>(...)`.
  let builders = [
    // Build a constant with a given constant tensor value.
    OpBuilder<(ins "DenseElementsAttr":$value), [{
      // Call into an autogenerated `build` method.
      build(builder, result, value.getType(), value);
    }]>,

    // Build a constant with a given constant floating-point value. This builder
    // creates a declaration for `ConstantOp::build` with the given parameters.
    OpBuilder<(ins "double":$value)>
  ];
}
```

**Specifying a Custom Assembly Format**

The printout version of IR has too much information.

We can strip out by implementing our owne oversion of print and parse function.

Take PrintOp as example.

```
void PrintOp::print(mlir::OpAsmPrinter &printer) {
  printer << "toy.print " << op.input();
  printer.printOptionalAttrDict(op.getAttrs());
  printer << " : " << op.input().getType();
}

mlir::ParseResult PrintOp::parse(mlir::OpAsmParser &parser,
                                 mlir::OperationState &result) {
...
}
```

### Chapter 3. High-level Language-Specific Analysis and Transformation

- Imperative, C++ Pattern match and Rewrite
- Decalrative, rule-based pattern-match and rewrite using table-driven

**C++**

```
/// Fold transpose(transpose(x)) -> x
struct SimplifyRedundantTranspose : public mlir::OpRewritePattern<TransposeOp> {
  SimplifyRedundantTranspose(mlir::MLIRContext *context)
      : OpRewritePattern<TransposeOp>(context, /*benefit=*/1) {}
  llvm::LogicalResult
  matchAndRewrite(TransposeOp op,
                  mlir::PatternRewriter &rewriter) const override {
    // Look through the input of the current transpose.
  ....
  }
};

// Register our patterns for rewrite by the Canonicalization framework.
void TransposeOp::getCanonicalizationPatterns(
    RewritePatternSet &results, MLIRContext *context) {
  results.add<SimplifyRedundantTranspose>(context);
}

// Add into Pass Manager
mlir::PassManager pm(module->getName());
pm.addNestedPass<mlir::toy::FuncOp>(mlir::createCanonicalizerPass());
```

**rule-based pattern-match and rewrite (DRR)**

```
def TypesAreIdentical : Constraint<CPred<"$0.getType() == $1.getType()">>;
def RedundantReshapeOptPattern : Pat<
  (ReshapeOp:$res $arg), (replaceWithValue $arg),
  [(TypesAreIdentical $res, $arg)]>;
```

