---
title: GPU TLB
date: 2024-08-26
permalink: /pages/45877/
---

1. [90] Dissecting the NVIDIA Volta GPU Architecture via Microbenchmaring
2. [6] SnakeByte: A TLB Design with Adaptive and Recursive Page Merging in GPUs

---

### 1. Dissecting the NVIDIA Volta GPU Architecture via Microbenchmaring
On Volta and on all other architectures we examined:
- the L1 data cache is indexed by virtual addresses;
- the L2 data cache is indexed by physical addresses

### 2. SnakeByte: A TLB Design with Adaptive and Recursive Page Merging in GPUs

#### Idea
SnakeByte allows multiple equal-sized pages coalescing into a page table entry (PTE).\
It records the validity of pages to be merged using a bit vector, and few bits are annexed to indicate the size of merged pages. 

#### TLB & PTW & GMMU
Departing from conventional paging schemes of CPUs that heavily rely on operating systems, hardware-based GPU memory management units (GMMUs) are essential to effectively separate device memory management from host
CPUs.\
Otherwise, GPUs require the frequent intervention of OS to handle page table walks (PTWs) and TLB misses, which significantly penalize the GPU performance.

Observations:
- GPU workloads demand a large number of TLB entries (e.g., 32K to 256K entries) to handle sizable working sets, but conventional TLBs cannot provide sufficient coverage.
- GPU workloads have variable ranges of page contiguity.

![image](https://github.com/user-attachments/assets/ca8c2089-866b-4c16-a853-3a0f2fc792bc)

