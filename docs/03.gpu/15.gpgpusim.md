---
title: Understanding GPGPU-SIM & GPGPU-SIM UVM_SMART (4)
date: 2024-08-14
permalink: /pages/45872/
---

### What is the microarchitecture of GPGPU-SIM?

![image](https://github.com/user-attachments/assets/7829ceea-eb93-4d2d-8896-edc3eb2dbe66)

#### shader_core_ctx

This should be the streaming multiprocessors that exeutes at warp level and shares the same L1 cache.

```
// @@@@@@ shader.cc
shader_core_ctx::shader_core_ctx( class gpgpu_sim *gpu, 
                                  class simt_core_cluster *cluster,
                                  unsigned shader_id,
                                  unsigned tpc_id,
                                  const struct shader_core_config *config,
                                  const struct memory_config *mem_config,
                                  shader_core_stats *stats,
				  class gpgpu_new_stats *new_stats )
   : core_t( gpu, NULL, config->warp_size, config->n_thread_per_shader ),
     m_barriers( this, config->max_warps_per_shader, config->max_cta_per_core, config->max_barriers_per_cta, config->warp_size ),
     m_dynamic_warp_id(0)
{
    ...
    m_L1I = new read_only_cache( name,m_config->m_L1I_config,m_sid,get_shader_instruction_cache_id(),m_icnt,IN_L1I_MISS_QUEUE);
    ...
    m_warp.resize(m_config->max_warps_per_shader, shd_warp_t(this, warp_size));
    m_scoreboard = new Scoreboard(m_sid, m_config->max_warps_per_shader);
}

// different stages:
{
    void decode();
    
    void issue();
    friend class scheduler_unit; //this is needed to use private issue warp.
    friend class TwoLevelScheduler;
    friend class LooseRoundRobbinScheduler;
    void issue_warp( register_set& warp, const warp_inst_t *pI, const active_mask_t &active_mask, unsigned warp_id );
    void func_exec_inst( warp_inst_t &inst );

     // Returns numbers of addresses in translated_addrs
    unsigned translate_local_memaddr( address_type localaddr, unsigned tid, unsigned num_shader, unsigned datasize, new_addr_type* translated_addrs );

    void read_operands();
    
    void execute();
    
    void writeback();
}
```

#### simt_core_cluster

This should be at GPU level.

```
// @@@@@@ shader.cc
class simt_core_cluster {
public:
    simt_core_cluster( class gpgpu_sim *gpu, 
                       unsigned cluster_id, 
                       const struct shader_core_config *config, 
                       const struct memory_config *mem_config,
                       shader_core_stats *stats,
                       memory_stats_t *mstats,
		       class gpgpu_new_stats *new_stats ) {

  }
}

simt_core_cluster::simt_core_cluster( class gpgpu_sim *gpu, 
                                      unsigned cluster_id, 
                                      const struct shader_core_config *config, 
                                      const struct memory_config *mem_config,
                                      shader_core_stats *stats, 
                                      class memory_stats_t *mstats,
				      class gpgpu_new_stats *new_stats )
{
    m_config = config;
    m_cta_issue_next_core=m_config->n_simt_cores_per_cluster-1; // this causes first launch to use hw cta 0
    m_cluster_id=cluster_id;
    m_gpu = gpu;
    m_stats = stats;
    m_memory_stats = mstats;
    
    m_new_stats = new_stats;

    m_core = new shader_core_ctx*[ config->n_simt_cores_per_cluster ];
    for( unsigned i=0; i < config->n_simt_cores_per_cluster; i++ ) {
        unsigned sid = m_config->cid_to_sid(i,m_cluster_id);
        m_core[i] = new shader_core_ctx(gpu,this,sid,m_cluster_id,config,mem_config,stats, new_stats);
        m_core_sim_order.push_back(i); 
    }
}
```

#### how thread block is issued to stream multiprocessor?

gpgpu-sim cycle() function
```
// @@@@@@ gpgpu_sim
void gpgpu_sim::cycle()
{
    ...
    m_cluster[i]->icnt_cycle();
    ...
    m_memory_partition_unit[i]->dram_cycle();
    ...
    m_memory_sub_partition[i]->cache_cycle(gpu_sim_cycle+gpu_tot_sim_cycle);
    ...
    icnt_transfer();
    ...
    for (unsigned i=0;i<m_shader_config->n_simt_clusters;i++) {
        if (m_cluster[i]->get_not_completed() || get_more_cta_left() ) {
            m_cluster[i]->core_cycle();
            *active_sms+=m_cluster[i]->get_n_active_sms();
         }
    }
    issue_block2core();
}

void gpgpu_sim::issue_block2core()
{
    unsigned last_issued = m_last_cluster_issue; 
    for (unsigned i=0;i<m_shader_config->n_simt_clusters;i++) {
        unsigned idx = (i + last_issued + 1) % m_shader_config->n_simt_clusters;
        unsigned num = m_cluster[idx]->issue_block2core();
        if( num ) {
            m_last_cluster_issue=idx;
            m_total_cta_launched += num;
        }
    }
}
```

simt_core_cluster issue block to stream multiprocessr.
```
// @@@@@@ shader.cc
unsigned simt_core_cluster::issue_block2core()
{
    unsigned num_blocks_issued=0;
    for( unsigned i=0; i < m_config->n_simt_cores_per_cluster; i++ ) {
        unsigned core = (i+m_cta_issue_next_core+1)%m_config->n_simt_cores_per_cluster;

        kernel_info_t * kernel;

        if(m_config->gpgpu_concurrent_kernel_sm) {//concurrent kernel on sm 
            //always select latest issued kernel
            kernel_info_t *k = m_gpu->select_kernel();
            kernel = k;
        }
	...

        if( m_gpu->kernel_more_cta_left(kernel) && 
            m_core[core]->can_issue_1block(*kernel)) {
            m_core[core]->issue_block2core(*kernel);
            ...
        }
    }
    return num_blocks_issued;
}
```

### configuration file

./config/GeForceGTX1080Ti/gpgpusim.config

gpgpu_n_clusters means the number of stream multiprocessing cores
```
# high level architecture configuration
-gpgpu_n_clusters 28

```
