---
title: GPU Training Notes
date: 2024-09-08
permalink: /pages/45884/
---

Notes from [Youtube Link](https://www.youtube.com/playlist?list=PL6RdenZrxrw-zNX7uuGppWETdxt_JxdMj)

## 6. Managed Memory
Managed Memory does not promise performance.\
It only paves ways for software programmer. For example, deepcopy.

We could restore the performance by using cudaMemPrefetchAsync

![image](https://github.com/user-attachments/assets/1466b29c-f4d9-4b8f-9535-b9f70de68b11)

**UM cannot do better than expertly written manual data movement, in most cases**

- Unified Memory: Page-faulting
- ATS: Nvidia with Power9. ATS service allows GPU to access CPU (Malloc) Memory\
  Only works in Power9, not for X86.
- HMM: Nvidia is working on HMM to allow similar with ATS.

![image](https://github.com/user-attachments/assets/4ed00e8e-9afb-45d6-bf56-7faf95801a64)

**cudaDeviceSynchronize() function is necessary**

After cudaLaunch kernel, CPU can execute immedidately, which might read data that has not been processed by GPU yet.\
Thus, synchronize to wait GPU finishing the processing.

---

## 7. Concurrency

### Pin Memory
- Statically allocated in Physical Memory.
- Stay out of paging system.

### Streams

- Sequential in Stream
- No order among Streams

![image](https://github.com/user-attachments/assets/5f2b4794-c6ab-46b5-89c8-97e8d95a0a16)

host Code could also be put into streams.

**Migration(unified memory) call could be more expensive than memcopy.**
- memcopy is handled by hardware engine
- unfied memory operate at page level and needs update of page tables.

### CUDA Event
Most used in timing.

### Concurrent Kernels
*Less efficient than saturating the device with a single kernel.*

Scheduler might launch blocks from one kernel as much as much possible, try to exhaust the GPU.\
If any resource is totally token, other kenel cannot launch.

### CUDA Graph

---

## 8. GPU Performance Analysis
