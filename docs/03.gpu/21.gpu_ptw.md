---
title: gpu page table walk
date: 2024-08-29
permalink: /pages/45878/
---

1. [117] Observations and Opportunities in Architecting Shared Virtual Memory for Heterogeneous Systems :+1: :+1: :+1: :+1: :older_man:
2. [68] Sheduling Page Table Walks for Irregular GPU Applications


---
# 2. Sheduling Page Table Walks for Irregular GPU Applications
- better forward progress is achieved by prioritizing translation requests from the instructions that require less work to service their
address translation needs.
- batching walk requests originating from the same SIMD instruction could reduce unnecessary stalls.

## Background 
real hardware demonstrated that such divergent memory accesses can slow down an irregular GPU application by up to 3.7-4Ã— due to address translation overheads alone [5].\
The study found that the negative impact of divergence could be greater on address translation than on the caches.

Due to the lack of sufficient spatial locality in such irregular applications, these requests often miss in TLBs, each generating a page table walk request.

we show that the order in which page table walk requests are serviced is also critical.

*First*, the number of page table walks generated due to the execution of a single SIMD memory instruction can vary widely based on how many distinct pages the instruction accesses and the TLB hits/misses it generates.
a completely divergent SIMD instruction can generate page table walk requests equal to the number of workitems in the wavefront (here, 64).\
*Second*, each page walk may itself need anywhere between one to four memory requests to complete.\
This happens due to hits/misses in page walk caches (PWCs) that store recently-used upperlevel entries of four-level page tables (d

## Idea

![image](https://github.com/user-attachments/assets/580b28d0-71f8-428a-852a-514204e070ed)

![image](https://github.com/user-attachments/assets/56b3c46e-9db9-4b8e-bcf1-7066487b4d51)


