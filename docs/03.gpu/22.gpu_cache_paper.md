---
title: GPU Cache's Papers
date: 2024-09-06
permalink: /pages/45879/
---

1. [22] Adaptive Memory-Side Last-Level GPU Chacing


---

# 1. Adaptive Memory-Side Last-Level GPU Chacing
## Introduction

GPUs typically feature a two-level on-chip cache hierarchy in which the first-level caches are private to each SM while the last-level cache (LLC) is a shared memory-side cache that is partitioned into
equally-sized slices and accessed via the NoC.

In fact, we find that GPU workloads have large read-only shared data footprints. For such sharing-intensive workloads, multiple SMs experience a bandwidth bottleneck when
they serialize on accesses to the same shared cache line.

While this is a practical solution for a limited number of cores in a CPU, it does not scale to a large number of SMs due to limitations in scaling GPU die size.

Shared LLCs incur a performance bottleneck for workloads that frequently access data shared by multiple SMs.

A shared memory-side LLC consists of multiple slices each caching a specific memory partition, i.e., a specific address range of the entire memory space is served by a particular
memory controller.

As a result, **a shared cache line appears in a single LLC slice, which leads to a severe performance bottleneck if multiple SMs concurrently access the same shared data.**

We find that GPU applications with **high degrees of read-only data sharing significantly benefit from a private LLC organization.**

To that end, this paper proposes adaptive memory-side caching to dynamically choose between a shared or private memory-side LLC.

These observations suggest an opportunity to improve performance by dynamically adapting a memory-side LLC to the needs of an applicationâ€™s sharing behavior.

**adaptive memory-side caching to dynamically choose between a shared or private memory-side LLC.** \
Selecting a shared versus private LLC is done using a lightweight performance model.

By default, the GPU assumes a shared LLC.

Profiling information is periodically collected to predict LLC miss rate and bandwidth under a private LLC organization while executing under a shared LLC. If deemed beneficial, the LLC is adapted to
a private cache.

The LLC reverts back to a shared organization periodically and when a new kernel gets launched.

### Main Idea

Private LLC could have replicate data, but waste memory space.

Shared LLC could access shared data a lot, introducing bottleneck.

Switch between those two modes.

![image](https://github.com/user-attachments/assets/8138dd9c-12e8-430d-8c65-43cae6d84a53)
