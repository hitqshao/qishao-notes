---
title: Understanding GPGPU-SIM & GPGPU-SIM UVM_SMART (1)
date: 2024-08-12
permalink: /pages/458725/
---

- libcuda
  * cuda_runtime_api.cc
- src
  * abstract_hardware_model.h/cpp
  * gpgpusim_entrypoint.h/cpp
  * stream_manager.h/cpp
  * cuda-sim
    - cuda-sim.h/cc
      :honeybee:
      ```
      void function_info::ptx_assemble() {
       for ( i=m_instructions.begin(); i != m_instructions.end(); i++ ) {
        // map pc to instruction
        g_pc_to_finfo[PC] = this;
        // This is a uniform array, each entry is one instruction
        m_instr_mem[n] = pI; 
        s_g_pc_to_insn.push_back(pI);
        ssert(pI == s_g_pc_to_insn[PC]);
        pI->set_m_instr_mem_index(n);
        pI->set_PC(PC);
       }
      }
      ```
    - memory.h/cc
    - opcode.h/def
    - ptx_loader.h/cc
    - ptx.y\
      It is a Yacc/Bison grammar file used to parse PTX (Parallel Thread Execution) assembly code, which is a low-level intermediate representation used by NVIDIA GPUs.\
      It defines the grammar rules for PTX assembly code and specifies how different components of PTX code should be interpreted and processed.\
      This includes recognizing various PTX instructions, operands, directives, and control structures, and translating them into an internal representation that the simulator can work with.
   
      When it meets instruction statement it will call add_instruction.
      ```
      statement_list: directive_statement { add_directive(); }
      | instruction_statement { add_instruction();}
      ...
      ```
    - ptx_parser.h/cc
      the add_instruction used in ptx.y will call the following instruction.
      ```
      void add_instruction() 
      {
      ptx_instruction *i = new ptx_instruction(**);
      g_instructions.push_back(i);
      }
      ```
      in the end of function it will add all the instructins into function infomation
      ```
      void end_function()
      {
      ...
      g_func_info->add_inst( g_instructions );
      ...
      }
      ```
    - ptx_ir.h/cc
      ```
      //@@@@@@ ptx_ir.h
      ...
      std::vector<const symbol*> m_args;
      // end_function will put function into this list
      std::list<ptx_instruction*> m_instructions;
      std::vector<basic_block_t*> m_basic_blocks;

      //@@@@@@ ptx_ir.cc
      void gpgpu_ptx_assemble( std::string kname, void *kinfo ) {
       function_info *func_info = (function_info *)kinfo;
       // This will call cuda_sim ptx_assemble function
       func_info->ptx_assemble();
      }
      ```
    - ptx_sim.h/cc
  * gpgpu-sim
    - gpgpu-sim.h/cc
    - shader.h/shader.cc
    - mem_fetch.h/cc
    - stack.h/cc
    - addrdec.h/cc
    - dram.h/cc
    - traffic_breakdown.h/cc




### How did GPGPU-sim get instruction from CUDA?

:honeybee: show how Yacc/Bison grammar file is used to add instruction in function_info.
Now we will describe how GPGPU-sim execute each instructin.

#### Function Mode

abstract_hardware_model.cc implement this function, if you provde a warpId, it can return warp_instruction.\
Thus, if we know next pc, we can use ptx_fetch_inst to get instruction.
```
// @@@@@@ abstract_hardware_model.cc
//! Get the warp to be executed using the data taken form the SIMT stack
warp_inst_t core_t::getExecuteWarp(unsigned warpId)
{
    unsigned pc,rpc;
    m_simt_stack[warpId]->get_pdom_stack_top_info(&pc,&rpc);
    warp_inst_t wi= *ptx_fetch_inst(pc);
    wi.set_active(m_simt_stack[warpId]->get_active_mask());
    return wi;
}
```

gpgpu*_sim_main_function -> gpgpu_cuda_ptx_sim_main_func -> execute -> executeWarp -> getExecuteWarp,execute_warp_inst_t

```
// @@@@@@ gpgpusim_entrypoint.cc
int gpgpu_opencl_ptx_sim_main_func( kernel_info_t *grid )
{
    //calling the CUDA PTX simulator, sending the kernel by reference and a flag set to true,
    //the flag used by the function to distinguish OpenCL calls from the CUDA simulation calls which
    //it is needed by the called function to not register the exit the exit of OpenCL kernel as it doesn't register entering in the first place as the CUDA kernels does
   gpgpu_cuda_ptx_sim_main_func( *grid, true );
   return 0;
}

// @@@@@@ cuda-sim.cc
/*!
This function simulates the CUDA code functionally, it takes a kernel_info_t parameter 
which holds the data for the CUDA kernel to be executed
!*/
void gpgpu_cuda_ptx_sim_main_func( kernel_info_t &kernel, bool openCL ) {
  while(!kernel.no_more_ctas_to_run()){
    functionalCoreSim cta(&kernel,g_the_gpu,
    g_the_gpu->getShaderCoreConfig()->warp_size
    );
    cta.execute();
 }
}


void functionalCoreSim::execute()
 {
    ...
    //start executing the CTA
    while(true){
        ...
        for(unsigned i=0;i<m_warp_count;i++){
            executeWarp(i,allAtBarrier,someOneLive);
        }
        ...
    }
 }

void functionalCoreSim::executeWarp(unsigned i, bool &allAtBarrier, bool & someOneLive)
{
 ...
 warp_inst_t inst =getExecuteWarp(i);
 //!!!!! Attention !!!!!!!!
 execute_warp_inst_t(inst,i);
 ...
 updateSIMTStack( i, &inst );
}

const warp_inst_t *ptx_fetch_inst( address_type pc )
{
    return function_info::pc_to_instruction(pc);
}

// @@@@@@ ptx_ir.h
static const ptx_instruction* pc_to_instruction(unsigned pc) 
{
  if( pc < s_g_pc_to_insn.size() )
      return s_g_pc_to_insn[pc];
  else
      return NULL;
}
```
#### Timing Mode

- shader.cc decode() fill instruction into ibuffer
- shader.h filled into m_ibuffer
- shader.cc cycle issue warp
  
```
// @@@@@@ shader.cc
void shader_core_ctx::decode()
{
    if( m_inst_fetch_buffer.m_valid ) {
        // decode 1 or 2 instructions and place them into ibuffer
        address_type pc = m_inst_fetch_buffer.m_pc;
        const warp_inst_t* pI1 = ptx_fetch_inst(pc);
        m_warp[m_inst_fetch_buffer.m_warp_id].ibuffer_fill(0,pI1);
        m_warp[m_inst_fetch_buffer.m_warp_id].inc_inst_in_pipeline();
        ...
    }
}

// @@@@@@ shader.h
    void ibuffer_fill( unsigned slot, const warp_inst_t *pI )
    {
       m_ibuffer[slot].m_inst=pI;
       m_ibuffer[slot].m_valid=true;
    }

    const warp_inst_t *ibuffer_next_inst() { return m_ibuffer[m_next].m_inst; }
```
Every cycle, if current warp is done, it will pick form the m_next_cycle_prioritized_warps to schedule next warp.\
The instruction is obtained from m_ibuffer.
```
void scheduler_unit::cycle()
{
    SCHED_DPRINTF( "scheduler_unit::cycle()\n" );
    bool valid_inst = false;  // there was one warp with a valid instruction to issue (didn't require flush due to control hazard)
    bool ready_inst = false;  // of the valid instructions, there was one not waiting for pending register writes
    bool issued_inst = false; // of these we issued one

    order_warps();
    for ( std::vector< shd_warp_t* >::const_iterator iter = m_next_cycle_prioritized_warps.begin();
          iter != m_next_cycle_prioritized_warps.end();
          iter++ ) {
        // Don't consider warps that are not yet valid
        if ( (*iter) == NULL || (*iter)->done_exit() ) {
            continue;
        }
        while( !warp(warp_id).waiting() && !warp(warp_id).ibuffer_empty() && (checked < max_issue) && (checked <= issued) && (issued < max_issue) ) {
            const warp_inst_t *pI = warp(warp_id).ibuffer_next_inst();
            if( pI ) {
            ...
              if ( (pI->op == LOAD_OP) || (pI->op == STORE_OP) || (pI->op == MEMORY_BARRIER_OP) ) {
                m_shader->issue_warp(*m_mem_out,pI,active_mask,warp_id);
                issued++;
                issued_inst=true;
                warp_inst_issued = true;
              } else if ( (pI->op == SFU_OP) || (pI->op == ALU_SFU_OP) ) {
                m_shader->issue_warp(*m_sfu_out,pI,active_mask,warp_id);
              }
            }
        }
    }
  }
```
