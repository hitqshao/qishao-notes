---
title: CUDA LayerNorm
date: 2024-12-29 15:32:49
permalink: /pages/f00007/
---

# CUDA LayerNorm

[Figure Source](https://oneflow2020.medium.com/how-to-implement-an-efficient-layernorm-cuda-kernel-oneflow-performance-optimization-731e91a285b8)

Formula
![image](https://github.com/user-attachments/assets/b6e1011f-d52f-41e4-a5fb-9e27429a3671)

## Keynotes:
- online algorthim to reduce pass
- warp shuffle for warp-level synchronization
- shared memory cache input vector in first pass, which could be reused in the future
- float4 for global memory coalesce

The performance improvement from last two optimization is obvious in this algorithm.
 
## Basic Flow

normally it needs two pass:
- collect mean
- calculate variance

After those two passes, we obtain mean and variance.
The last extra pass, we calculate elementwise normalization.

```
        for (int i = 0; i < C; ++i) {
            mean += x[i];
        }
        mean /= C;

        float var = 0.f;
        for (int i = 0; i < C; ++i) {
            float xShift = x[i] - mean;
            var += xShift * xShift;
        }
        float inv_std = 1.0f / sqrt(var / C + eps);

        for (int i = 0; i < C; ++i) {
            y[i] = weight[i] * (x[i] - mean) * inv_std + bias[i];
        }
```

## Naive algorithm


![image](https://github.com/user-attachments/assets/8ad186d7-bc9f-4b08-8333-0a5cc649e41f)

This naive algorithm reduce first two pass into single pass.\
In one pass, it calculates mean and variance.

```
            float *const x = input + row * C;
            float *const y = output + row * C;
            float partialSum = 0.0f;
            float partialSum2 = 0.0f;
            for (int i = laneId; i < C; i += warpSize) {
                float xi = x[i];
                partialSum += xi;
                partialSum2 += xi * xi;
            }

            float mean = warpReduceSum(partialSum) / C;
            float mean2 = warpReduceSum(partialSum2) / C;

            float var = (mean2 - mean * mean);
            float inv_std = rsqrtf(var + eps);

            for (int i = laneId; i < C; i += warpSize) {
                y[i] = weight[i] * (x[i] - mean) * inv_std + bias[i];
            }
```

## Welford' online algorthim

![image](https://github.com/user-attachments/assets/cb3e0b0b-d69b-4c52-9d38-28482b045b9d)

This is also single-pass algorithm and numerically stable.

```
            for (int i = laneId; i < C; i += warpSize) {
                float xi = x[i];
                n++;
                float delta = xi - mean;
                mean += delta / n;
                float delta2 = xi - mean;
                M2 += delta * delta2;
            }

            welfordWarpReduce(mean,M2,n,&shared[warpId*2],&shared[warpId*2+1]);

            float global_mean = shared[warpId*2];
            float global_var = shared[warpId*2+1];
          
            float inv_std = rsqrtf(global_var + eps);

            for (int i = laneId; i < C; i += warpSize) {
                y[i] = weight[i] * (x[i] - global_mean) * inv_std + bias[i];
            }
```




