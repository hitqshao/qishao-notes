---
title: CUDA Piceces
date: 2025-01-10 15:32:49
permalink: /pages/f00010/
---

# CUDA Piceces

## bank conflict in shared memory

[nvidia-forum](https://forums.developer.nvidia.com/t/how-to-understand-the-bank-conflict-of-shared-mem/260900)

Largest transaction size is 128 bytes(32 thread, 4 byte for each thread).

If each thread access 16 bytes, Thread0 -Thread7 will issue one transaction.\
Thread 8 - Thread15 will issue another transaction.

![image](https://github.com/user-attachments/assets/4e9c1b49-85fc-4804-89af-4dec43146c74)

In this case, even thread 0 and thread 8 shares the same bank.\
As long as they are not in the same transaction, there would be no bank conflict.

## open-source implementation to achieve 95% cuBLAS performance
[95% cuBLAS](https://accu.org/journals/overload/32/181/schuetze/)

[github](https://github.com/qishao-chalmers/CudaTensorCoreHGEMM)

Main Idea:
- double buffer
- async loading

## Vectorized Memory Access

[Vectorized Memory Access- LeiMao](https://leimao.github.io/blog/CUDA-Vectorized-Memory-Access/)
[CUDA Pro Tip](https://developer.nvidia.com/blog/cuda-pro-tip-increase-performance-with-vectorized-memory-access/)

This blog conduct experiments on 4byte/8byte/16byte per thread accessing global memory.

16-byte per thread achieves effective memory bandwidth.

This might explain why float4 works.

- higher memory bandwidth usage
- less instruction

