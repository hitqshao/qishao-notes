<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>how llm works | CPU &amp; GPU Microarch. Qi Shao</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="stylesheet" href="custom.css">
    <script language="javascript" type="text/javascript" src="/qishao-notes/js/pgmanor-self.js"></script>
    <meta name="description" content="Computer System">
    <meta name="google-site-verification" content="66w5U9NY5gJWu7iBtHKMbhpXkV94jy31L_RHbvrZZzY">
    <meta name="keywords" content="Hitqishao,golang,vue,go-web,go-admin,go-ldap-admin">
    <meta name="theme-color" content="#11a8cd">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <link rel="preload" href="/qishao-notes/assets/css/0.styles.922e50b3.css" as="style"><link rel="preload" href="/qishao-notes/assets/js/app.8b6f5ebd.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/2.523d320d.js" as="script"><link rel="preload" href="/qishao-notes/assets/js/71.ae3a80bd.js" as="script"><link rel="prefetch" href="/qishao-notes/assets/js/10.7da5f974.js"><link rel="prefetch" href="/qishao-notes/assets/js/11.3efa7066.js"><link rel="prefetch" href="/qishao-notes/assets/js/12.6f01e13b.js"><link rel="prefetch" href="/qishao-notes/assets/js/13.bab014fa.js"><link rel="prefetch" href="/qishao-notes/assets/js/14.50f4b9ea.js"><link rel="prefetch" href="/qishao-notes/assets/js/15.a1c8051e.js"><link rel="prefetch" href="/qishao-notes/assets/js/16.9230cfc6.js"><link rel="prefetch" href="/qishao-notes/assets/js/17.ae36d225.js"><link rel="prefetch" href="/qishao-notes/assets/js/18.fee73de1.js"><link rel="prefetch" href="/qishao-notes/assets/js/19.c7571ae9.js"><link rel="prefetch" href="/qishao-notes/assets/js/20.d3f8525c.js"><link rel="prefetch" href="/qishao-notes/assets/js/21.49c6d2ea.js"><link rel="prefetch" href="/qishao-notes/assets/js/22.ba0fe314.js"><link rel="prefetch" href="/qishao-notes/assets/js/23.9570c32e.js"><link rel="prefetch" href="/qishao-notes/assets/js/24.b306d031.js"><link rel="prefetch" href="/qishao-notes/assets/js/25.2f031b99.js"><link rel="prefetch" href="/qishao-notes/assets/js/26.70bdafd9.js"><link rel="prefetch" href="/qishao-notes/assets/js/27.215d3799.js"><link rel="prefetch" href="/qishao-notes/assets/js/28.5107c8bb.js"><link rel="prefetch" href="/qishao-notes/assets/js/29.51151c6e.js"><link rel="prefetch" href="/qishao-notes/assets/js/3.c4ba35c4.js"><link rel="prefetch" href="/qishao-notes/assets/js/30.6073ba53.js"><link rel="prefetch" href="/qishao-notes/assets/js/31.9b1d9797.js"><link rel="prefetch" href="/qishao-notes/assets/js/32.9d1d24bd.js"><link rel="prefetch" href="/qishao-notes/assets/js/33.2ef8d69f.js"><link rel="prefetch" href="/qishao-notes/assets/js/34.e8ab6db4.js"><link rel="prefetch" href="/qishao-notes/assets/js/35.fe7cb00f.js"><link rel="prefetch" href="/qishao-notes/assets/js/36.11c6f4e1.js"><link rel="prefetch" href="/qishao-notes/assets/js/37.66872961.js"><link rel="prefetch" href="/qishao-notes/assets/js/38.061b1e0f.js"><link rel="prefetch" href="/qishao-notes/assets/js/39.2a56cf48.js"><link rel="prefetch" href="/qishao-notes/assets/js/4.d64d6dfc.js"><link rel="prefetch" href="/qishao-notes/assets/js/40.a7c0efe8.js"><link rel="prefetch" href="/qishao-notes/assets/js/41.0ab282a7.js"><link rel="prefetch" href="/qishao-notes/assets/js/42.0bb4c060.js"><link rel="prefetch" href="/qishao-notes/assets/js/43.c3f5daa8.js"><link rel="prefetch" href="/qishao-notes/assets/js/44.0cd5af0e.js"><link rel="prefetch" href="/qishao-notes/assets/js/45.110761d4.js"><link rel="prefetch" href="/qishao-notes/assets/js/46.97c73808.js"><link rel="prefetch" href="/qishao-notes/assets/js/47.c4e75e7e.js"><link rel="prefetch" href="/qishao-notes/assets/js/48.4bd445ed.js"><link rel="prefetch" href="/qishao-notes/assets/js/49.8e959956.js"><link rel="prefetch" href="/qishao-notes/assets/js/5.067c8a2c.js"><link rel="prefetch" href="/qishao-notes/assets/js/50.05874901.js"><link rel="prefetch" href="/qishao-notes/assets/js/51.980add25.js"><link rel="prefetch" href="/qishao-notes/assets/js/52.963b7c30.js"><link rel="prefetch" href="/qishao-notes/assets/js/53.b630cb0c.js"><link rel="prefetch" href="/qishao-notes/assets/js/54.9bde7f7b.js"><link rel="prefetch" href="/qishao-notes/assets/js/55.17b1793c.js"><link rel="prefetch" href="/qishao-notes/assets/js/56.005dcbd7.js"><link rel="prefetch" href="/qishao-notes/assets/js/57.36430ee7.js"><link rel="prefetch" href="/qishao-notes/assets/js/58.18a2c4ea.js"><link rel="prefetch" href="/qishao-notes/assets/js/59.906732b8.js"><link rel="prefetch" href="/qishao-notes/assets/js/6.472961bb.js"><link rel="prefetch" href="/qishao-notes/assets/js/60.22dc04ee.js"><link rel="prefetch" href="/qishao-notes/assets/js/61.94fd64d5.js"><link rel="prefetch" href="/qishao-notes/assets/js/62.5e9f4e8d.js"><link rel="prefetch" href="/qishao-notes/assets/js/63.81d6c4bb.js"><link rel="prefetch" href="/qishao-notes/assets/js/64.7f44f718.js"><link rel="prefetch" href="/qishao-notes/assets/js/65.702900ed.js"><link rel="prefetch" href="/qishao-notes/assets/js/66.9907e336.js"><link rel="prefetch" href="/qishao-notes/assets/js/67.ce18761e.js"><link rel="prefetch" href="/qishao-notes/assets/js/68.3c4f4a9f.js"><link rel="prefetch" href="/qishao-notes/assets/js/69.0fb21244.js"><link rel="prefetch" href="/qishao-notes/assets/js/7.1e07ff8f.js"><link rel="prefetch" href="/qishao-notes/assets/js/70.5d3aa2ea.js"><link rel="prefetch" href="/qishao-notes/assets/js/72.975f3eaa.js"><link rel="prefetch" href="/qishao-notes/assets/js/73.f8673416.js"><link rel="prefetch" href="/qishao-notes/assets/js/74.71902f54.js"><link rel="prefetch" href="/qishao-notes/assets/js/75.9f731210.js"><link rel="prefetch" href="/qishao-notes/assets/js/76.846c5a16.js"><link rel="prefetch" href="/qishao-notes/assets/js/77.2c303460.js"><link rel="prefetch" href="/qishao-notes/assets/js/78.d47a5ecb.js"><link rel="prefetch" href="/qishao-notes/assets/js/79.fe561edf.js"><link rel="prefetch" href="/qishao-notes/assets/js/8.d2ade20f.js"><link rel="prefetch" href="/qishao-notes/assets/js/80.ed52a454.js"><link rel="prefetch" href="/qishao-notes/assets/js/81.cccdd380.js"><link rel="prefetch" href="/qishao-notes/assets/js/82.aebd4143.js"><link rel="prefetch" href="/qishao-notes/assets/js/83.6a3f4bc0.js"><link rel="prefetch" href="/qishao-notes/assets/js/84.84b51a9f.js"><link rel="prefetch" href="/qishao-notes/assets/js/85.8dacd654.js"><link rel="prefetch" href="/qishao-notes/assets/js/86.955a9e1c.js"><link rel="prefetch" href="/qishao-notes/assets/js/87.8b279594.js"><link rel="prefetch" href="/qishao-notes/assets/js/9.69a68d48.js">
    <link rel="stylesheet" href="/qishao-notes/assets/css/0.styles.922e50b3.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/qishao-notes/" class="home-link router-link-active"><!----> <span class="site-name">CPU &amp; GPU Microarch. Qi Shao</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/llm/" class="nav-link">ml&amp;llm</a></div><div class="nav-item"><a href="/qishao-notes/compiler/" class="nav-link">compiler</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/unix/" class="nav-link">unix</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><!----> <nav class="nav-links"><div class="nav-item"><a href="/qishao-notes/" class="nav-link">Home</a></div><div class="nav-item"><a href="/qishao-notes/gpu/" class="nav-link">gpu</a></div><div class="nav-item"><a href="/qishao-notes/cpu/" class="nav-link">cpu</a></div><div class="nav-item"><a href="/qishao-notes/llm/" class="nav-link">ml&amp;llm</a></div><div class="nav-item"><a href="/qishao-notes/compiler/" class="nav-link">compiler</a></div><div class="nav-item"><a href="/qishao-notes/hbm/" class="nav-link">hbm</a></div><div class="nav-item"><a href="/qishao-notes/unix/" class="nav-link">unix</a></div><div class="nav-item"><a href="https://blog.csdn.net/hit_shaoqi" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <a href="https://github.com/hitqshao/qishao-notes" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/qishao-notes/pages/dc7035/" aria-current="page" class="active sidebar-link">how llm works</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/qishao-notes/pages/dc7036/" class="sidebar-link">LLM Hardware Optimization</a></li><li><a href="/qishao-notes/pages/dc7037/" class="sidebar-link">How to run llama.cpp with gem5</a></li><li><a href="/qishao-notes/pages/dc7038/" class="sidebar-link">Memory Usage in Training LLM</a></li><li><a href="/qishao-notes/pages/dc7039/" class="sidebar-link">llm optimizations</a></li><li><a href="/qishao-notes/pages/dc7040/" class="sidebar-link">llm flash algorthms</a></li><li><a href="/qishao-notes/pages/dc7041/" class="sidebar-link">llm compute &amp; memory bound</a></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/qishao-notes/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/qishao-notes/llm/#llm" data-v-06225672>llm</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/hitqshao" target="_blank" title="作者" class="beLink" data-v-06225672>hitqishao</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2024-01-02</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABH1JREFUSA3tVl1oHFUUPmdmd2ltklqbpJDiNnXFmgbFktho7YMPNiJSSZM0+CAYSkUELVhM6YuwIPpgoOKDqOBDC0XE2CQoNtQXBUFTTcCi+Wlh1V2TQExsUzcltd3M9Tt3ZjZzZ2fT+OJTL8yeM+eee757fmeJbq//KQL8X3DUSFOcfr7cRsRtxNQMWueeVzOkaITIGqQHNg5y8+jNW9ldM7A6nTpAjuolUikAwq7CE3WcM2RRDz+XGVgN3FptU/aUSlvq9Pa3iZ1+sgAqJyyAFqkipd9dqiwHF3P65YycLWc/6sqGrvoEoIp6DOFaX5h6+dnfjkWprwqsPk0dUGq5vySwDImC10KxFHgGL1SWoc92O3eVht09qdXNH11I2SsTsJYqMWzihqGMi+A+Garf3BAuuLI5oGlULyNfyB/HYNujwktOfRrMr5t77NmevqaUopx0grnKAyvVpmwUDB4x6FPXuGvYLTDwWsejwgtgkYKPqRJg8SV6xaiZ3ZTppGneS4yfH5/66fZSDHv+QZci/+h5c5UHtpy67JUqGppM0sh0Nc1dW6/N1W5Yoqat8/TU/VnadmdeW2PLLSyh0cvxBs3KbqTmwYPpxN4do/mzE8nEpvX/UMu2Wbp74zUAK5q6WkHns7V0eWkdPbPzd3rxkTGybadYySumVzhcaJFbs5UrEkQ/+CK8gF5dnh/6ciIZ73gwQ927L1IitoxKLXYP3SjYdOrHHfTZhRRlFyrorafPk20B3HPD1y2G3qKZME5Jcf3t/HUC13/8tSd++vqFveMUTwAUxSUFI1QekR1+bIze3D9MF2aq6cPvG72CgnldWCFqyRw3lwH8ZMerjTD9ElRO7Gv44wNpC90aASqGfVlz/Rx17srQ57/UU26hkhQqUB7dBR71WmzQhHUnblGmVOEw0jhbV1n9OlXUDCIRGaNV5Jp43N516fN7JmnTHdfp7Hgy0luO4aMhtkLL8Bi3bUWYvzh5Mn1dTxrL6QmGuRhGL/TiTTxRoEdTszSaq9GR0NGA3KdkOz3hqSV3MIDhQ5IVX/Ivx3umBti2es2h4eZby7x8br1rkf7Mo90AqC8aQ3sJeNzqFRu+vSANAQe3PL7l0HGOAdwDCeZYvNKeoZp1Qfs6Aipndh86HmFRi0LAnEO47wsqM6cdfjh3jBPUzhZy7nvlUfFsamED1VQt6aISHVymXZ/B2aCtIG8AI8xfobj2d3en1wWVhOeHELKmLQ1s211s88comkv4UCwWyF787mJdYXtNfhKAXVqnKTq8QZvGAGGOfaTo5pGZ/PwbUCr5+DPr/1J92JNHr9aOl/F3iI5+O1nfybsGxoimvZ3ViWSluDITw3P37mypheDIPY0tw7+O/5ApbkYw+zpfaUVu32Pi98+defdUhEpZkRFq0aqyNh9FuL9hpYbEm6iwi0z2REd09ZmyENEbuhjDWzKvZXTqKYaBIr3tt5kuPtQBZFvEUwHt60vfCNu41XsksH9Ij1BMMz1Y0OOunHNShFIP5868g5zeXmuLwL9T4b6Q2+KejgAAAABJRU5ErkJggg==">how llm works<!----></h1> <!----> <div class="theme-vdoing-content content__default"><ol><li>LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem [2023]</li> <li>NVIDIA Mastering LLM Techniques</li></ol> <hr> <h3 id="_1-llm-as-os-agents-as-apps-envisioning-aios-agents-and-the-aios-agent-ecosystem-2012"><a href="#_1-llm-as-os-agents-as-apps-envisioning-aios-agents-and-the-aios-agent-ecosystem-2012" class="header-anchor">#</a> 1. LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem [2012]</h3> <p>👍
Analogy of LLM and OS.</p> <p>Blog: https://huggingface.co/blog/shivance/illustrated-llm-os</p> <p>Youtube: Andrej Karpathy https://www.youtube.com/watch?v=kCc8FmEb1nY</p> <p>Parallel decoding(Multi threading): This is a technique that allows multiple decoding processes to occur simultaneously, which can speed up the decoding process. For example, instead of generating one token at a time, parallel decoding can generate several tokens in parallel, using different models or different parts of the same model. This can reduce the latency and increase the throughput of the decoding process. A recent paper by Apple researchers proposed a method called Parallel Speculative Sampling (PaSS) that introduces parallel decoding for LLMs, maintaining model quality while achieving remarkable speed.
<strong>Related Paper</strong>: Accelerating LLM Inference with Staged Speculative Decoding</p> <p>Ensemble decoding(Multi processing): This is a technique that involves using multiple models to decode a single input sequence, which can improve the accuracy of the decoding process. For example, instead of relying on one model to generate the output, ensemble decoding can combine the outputs of several models, using methods such as voting, averaging, or reranking. This can increase the diversity and robustness of the decoding process. A common approach for ensemble decoding is to use models that have been trained with different architectures, hyperparameters, or data sources.</p> <p>Speculative execution: This is a technique that involves predicting the outcome of a computation before it is actually executed, which can speed up the decoding process. For example, instead of waiting for the final hidden state of the model to generate the next token, speculative execution can use the early hidden states to predict the next token and execute the model in parallel on the predicted token. This can reduce the dependency between tokens and increase the parallelism of the decoding process. A recent paper by Berkeley researchers proposed a method called SPEED, which improves inference efficiency by speculatively executing multiple future tokens in parallel with the current token using predicted values based on early-layer hidden states.</p> <p><strong>Related Paper</strong>: SPEED: Speculative Pipelined Execution for Efficient Decoding</p> <h3 id="_2-nvidia-mastering-llm-techniques"><a href="#_2-nvidia-mastering-llm-techniques" class="header-anchor">#</a> 2. NVIDIA Mastering LLM Techniques</h3> <p>Link: https://developer.nvidia.com/blog/search-posts/?q=Mastering+LLM+Techniques</p> <ol><li>Customization</li> <li>LLMOps</li> <li>Training</li> <li>Inference Optimization</li> <li></li></ol> <h3 id="_3-finetuning"><a href="#_3-finetuning" class="header-anchor">#</a> 3. Finetuning</h3> <ol><li>How RLHF Preference Model Tuning Works (And How Things May Go Wrong)
Blog: https://www.assemblyai.com/blog/how-rlhf-preference-model-tuning-works-and-how-things-may-go-wrong/</li></ol> <p>Paper: RRHF: Rank Responses to Align Language Models with Human Feedback without tears
2.</p> <h3 id="_4-function-calling"><a href="#_4-function-calling" class="header-anchor">#</a> 4. Function Calling</h3> <ol><li>Blog: https://crunchingthedata.com/when-to-use-function-calling-for-llms/</li> <li>Paper: An LLM Compiler for Parallel Function Calling</li></ol></div></div> <!----> <div class="page-edit"><div class="edit-link"><a href="https://github.com/hitqshao/qishao-notes/edit/main/docs/05.llm/01.How_LLM_Works.md" target="_blank" rel="noopener noreferrer">帮助我们改善此页面</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2024/12/09, 05:08:54</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><!----> <a href="/qishao-notes/pages/dc7036/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">LLM Hardware Optimization</div></a></div> <div class="page-nav"><p class="inner"><!----> <span class="next"><a href="/qishao-notes/pages/dc7036/">LLM Hardware Optimization</a>→
      </span></p></div></div></div> <!----></main></div> <div class="footer"><div class="icons"><a href="https://github.com/hitqshao" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="mailto:hitqshao@163.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://gitee.com/hitqshao" title="Gitee" target="_blank" class="iconfont icon-gitee"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2024
    <span>Eryajf | <a href="https://github.com/hitqshao/qishao-notes/blob/main/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><!----></div></div>
    <script src="/qishao-notes/assets/js/app.8b6f5ebd.js" defer></script><script src="/qishao-notes/assets/js/2.523d320d.js" defer></script><script src="/qishao-notes/assets/js/71.ae3a80bd.js" defer></script>
  </body>
</html>
