(window.webpackJsonp=window.webpackJsonp||[]).push([[64],{475:function(e,t,a){"use strict";a.r(t);var s=a(5),r=Object(s.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("ol",[t("li",[e._v("[24] RISCV2 A Scalable RISC-V Vector Processor")]),e._v(" "),t("li",[e._v("[7] Adaptable Register File Organization for Vector Processors")])]),e._v(" "),t("hr"),e._v(" "),t("h3",{attrs:{id:"_24-riscv2-a-scalable-risc-v-vector-processor"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_24-riscv2-a-scalable-risc-v-vector-processor"}},[e._v("#")]),e._v(" [24] RISCV2 A Scalable RISC-V Vector Processor")]),e._v(" "),t("p",[e._v("Coupled with dynamically allocated register, at run time, the new register remapping mechanism enables:")]),e._v(" "),t("ul",[t("li",[e._v("dynamic hardware-based loop unrolling")]),e._v(" "),t("li",[e._v("optimized instruction scheduling")])]),e._v(" "),t("p",[e._v("Decoupled execution scheme employs resource acquire-and-release semantics to disambiguate between parallel computation and memory-access instruction streams")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/3a7ef400-9ca7-406c-9df9-8e0281837dce",alt:"image"}})]),e._v(" "),t("h4",{attrs:{id:"register-remapping-and-dynamic-register-file-allocation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#register-remapping-and-dynamic-register-file-allocation"}},[e._v("#")]),e._v(" Register Remapping and dynamic register file allocation")]),e._v(" "),t("p",[e._v("Vector instruction operate on mutiple elements, the vIS stages transfroms vector instructions into multuple micro-operations(uops), each uop operating on a different register groups.")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/03117910-2565-4a3a-8175-bb7379e383e1",alt:"image"}})]),e._v(" "),t("p",[e._v("Each logic register is mapped to a group of reigster, instread of one-on-one  mapping.")]),e._v(" "),t("p",[e._v("The new reigster remapping mechanism facilitates dynamic loop unrolling in hardware.")]),e._v(" "),t("p",[e._v("The unrolling mitigates the stall incurred by data dependencies, since direct consumer of a result is now seperated from its producer by multiple uops.")]),e._v(" "),t("p",[e._v("Consequently, resource utilization increase substantially.")]),e._v(" "),t("h4",{attrs:{id:"decoupled-execution-computation-and-memory-access"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#decoupled-execution-computation-and-memory-access"}},[e._v("#")]),e._v(" Decoupled execution: computation and memory access")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/42c8825f-8082-4214-9317-cfdb0872f9e9",alt:"image"}})]),e._v(" "),t("p",[e._v("As to memory instructions that does not access execution lanes, they are routed after vRRM pipeline stage directly to the memory unit.")]),e._v(" "),t("p",[e._v("The memory unit features two parallel engines that allows the simultaneous processing and disambiguaing of one load and one store instructions.")]),e._v(" "),t("p",[e._v("Traditionally, synchronization is decoupled processor schemes is achieved by employing so called synchronization queues and specical move operation.")]),e._v(" "),t("p",[e._v("These are not amenable to vector processors. "),t("strong",[e._v("Here I dont understand.")])]),e._v(" "),t("p",[e._v("They keep a ghost copy of instructin dispatched to vIS stage which updates scoreboard, maintain the wakeup function.")])])}),[],!1,null,null,null);t.default=r.exports}}]);