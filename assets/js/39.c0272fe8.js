(window.webpackJsonp=window.webpackJsonp||[]).push([[39],{449:function(e,a,t){"use strict";t.r(a);var r=t(5),s=Object(r.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h2",{attrs:{id:"harnessing-integrated-cpu-gpu-system-memory-for-hpc-a-first-look-into-grace-hopper"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#harnessing-integrated-cpu-gpu-system-memory-for-hpc-a-first-look-into-grace-hopper"}},[e._v("#")]),e._v(" Harnessing Integrated CPU-GPU System Memory for HPC: a first look into Grace Hopper")]),e._v(" "),a("p",[e._v("üëç üëç üëç")]),e._v(" "),a("h3",{attrs:{id:"introduction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[e._v("#")]),e._v(" Introduction")]),e._v(" "),a("h4",{attrs:{id:"limitation-of-state-of-art"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#limitation-of-state-of-art"}},[e._v("#")]),e._v(" limitation of state-of-art")]),e._v(" "),a("ol",[a("li",[e._v("UVM large overheads in handling page faults in GPU and suffers from read/write amplification due to page-level swapping.")]),e._v(" "),a("li",[e._v("Data object offloading requires offline profiling and application refactoring, limiting solution generality.")]),e._v(" "),a("li",[e._v("The performance of both solutions is constrained by data transfer bottlenecks between the CPU and GPU.")])]),e._v(" "),a("h4",{attrs:{id:"grace-hopper-superchip"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#grace-hopper-superchip"}},[e._v("#")]),e._v(" Grace Hopper Superchip")]),e._v(" "),a("ul",[a("li",[e._v("NVLink-C2C (chip-to-chip)  cache-coherent interconnect")]),e._v(" "),a("li",[e._v("a single virtual memory space is shared between the CPU and GPU (i.e., system memory)")]),e._v(" "),a("li",[e._v("address translation is accelerated by hardware.\n"),a("ol",[a("li",[e._v("direct remote accesses at cacheline granularity")]),e._v(" "),a("li",[e._v("heuristic-guided page migrations.")])])])]),e._v(" "),a("p",[e._v("By leveraging cacheline level access and Address Translation Service (ATS), which enables full access to all CPU and GPU memory allocations, the system memory eliminates the page-fault handling\noverhead needed in managed memory in UVM, and minimizes the need for memory migrations.")]),e._v(" "),a("p",[e._v("While managed memory splits the virtual memory space into both the system page table and GPU page table, system memory relies on a single system-wide page table, shared between the CPU and the GPU.")]),e._v(" "),a("h3",{attrs:{id:"grace-hooper-unified-memory-system"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#grace-hooper-unified-memory-system"}},[e._v("#")]),e._v(" Grace Hooper Unified Memory System")]),e._v(" "),a("ul",[a("li",[e._v("system-allocated memory")]),e._v(" "),a("li",[e._v("CUDA managed memory")])]),e._v(" "),a("h4",{attrs:{id:"memory-subsystem"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#memory-subsystem"}},[e._v("#")]),e._v(" Memory Subsystem")])])}),[],!1,null,null,null);a.default=s.exports}}]);