(window.webpackJsonp=window.webpackJsonp||[]).push([[61],{512:function(e,a,r){"use strict";r.r(a);var t=r(8),n=Object(t.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("ol",[a("li",[e._v("[354] Benchmarking TPU, GPU, and CPU Platforms for Deep Learning")]),e._v(" "),a("li",[e._v("[59 Year:2019] Characterizing Deep Learning Training Workloads on Alibaba-PAI")]),e._v(" "),a("li",[e._v("[12] Effective Elastic Scaling of Deep Learning Workloads")]),e._v(" "),a("li",[e._v("[30 Year:2024] LLM Inference Unveiled: Survey and Roofline Model Insights")]),e._v(" "),a("li",[e._v("[1] Performance Modeling and Workload Analysis of Distributed Large Language Model Training and Inference")]),e._v(" "),a("li",[e._v("[Blog] LLM Inference Series: 5. Dissecting model performance")]),e._v(" "),a("li",[e._v("[47 Year:2024] Understanding LLMs: A Comprehensive Overview from Training to Inference")]),e._v(" "),a("li",[e._v("[37 Year:2022] Reveal training performance mystery between TensorFlow and PyTorch in the single GPU environment üëç  üëç  üëç  üëç  üëç")]),e._v(" "),a("li",[e._v("[46 Year:2019] Performance Characterization of DNN Training using TensorFlow and PyTorch on Modern Clusters")]),e._v(" "),a("li",[e._v("[163 Year:2020] Inducing and Exploiting Activation Sparsity for Fast Neural Network Inference")]),e._v(" "),a("li",[e._v("[204 Year:2016] Fathom: Reference Workloads for Modern Deep Learning Methods")])]),e._v(" "),a("hr"),e._v(" "),a("h3",{attrs:{id:"_1-benchmarking-tpu-gpu-and-cpu-platforms-for-deep-learning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-benchmarking-tpu-gpu-and-cpu-platforms-for-deep-learning"}},[e._v("#")]),e._v(" 1. Benchmarking TPU, GPU, and CPU Platforms for Deep Learning")]),e._v(" "),a("p",[e._v("Paper from Harvard")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/110ddbc0-1ddf-40fa-b360-9e3f589494c6",alt:"image"}})]),e._v(" "),a("hr"),e._v(" "),a("h3",{attrs:{id:"_2-59-year-2019-characterizing-deep-learning-training-workloads-on-alibaba-pai"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-59-year-2019-characterizing-deep-learning-training-workloads-on-alibaba-pai"}},[e._v("#")]),e._v(" 2 [59 Year:2019] Characterizing Deep Learning Training Workloads on Alibaba-PAI")]),e._v(" "),a("p",[e._v("This paper compares early ml, like single node, single master multi worker, nvlinkd is just introduced to Alibaba at that time.")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/8e9eb798-a1bf-48da-aa17-d30c7e6973fc",alt:"image"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/ec5cdae5-2150-48aa-9626-37869115bff7",alt:"image"}})]),e._v(" "),a("hr"),e._v(" "),a("h3",{attrs:{id:"_10-inducing-and-exploiting-activation-sparsity-for-fast-neural-network-inference"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_10-inducing-and-exploiting-activation-sparsity-for-fast-neural-network-inference"}},[e._v("#")]),e._v(" 10. Inducing and Exploiting Activation Sparsity for Fast Neural Network Inference")]),e._v(" "),a("p",[e._v("Sparsity across channels:")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/d0ab98ae-adcd-438a-97fe-db8c31becb3f",alt:"image"}})]),e._v(" "),a("p",[e._v("Sparsity across layers:\n"),a("img",{attrs:{src:"https://github.com/user-attachments/assets/68c5159a-f536-4714-aadf-0772b6c73dde",alt:"image"}})]),e._v(" "),a("p",[a("em",[a("strong",[e._v("CSCC: Convolution Split Compression Calculation Algorithm for Deep Neural Network")])]),e._v("\nSparsity across layers:\n"),a("img",{attrs:{src:"https://github.com/user-attachments/assets/0496984d-6cad-4727-8ee7-f63023a1656c",alt:"image"}})]),e._v(" "),a("hr"),e._v(" "),a("h3",{attrs:{id:"_11-fathom-reference-workloads-for-modern-deep-learning-methods"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_11-fathom-reference-workloads-for-modern-deep-learning-methods"}},[e._v("#")]),e._v(" 11.Fathom: Reference Workloads for Modern Deep Learning Methods")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/04833dea-d804-416e-914f-d59409ab0f5e",alt:"image"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/4394bb14-fd24-46de-a604-f34b692fd139",alt:"image"}})]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/39728745-788b-4ac1-b777-937f25b9083d",alt:"image"}})])])}),[],!1,null,null,null);a.default=n.exports}}]);