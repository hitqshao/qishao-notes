(window.webpackJsonp=window.webpackJsonp||[]).push([[50],{461:function(e,t,a){"use strict";a.r(t);var s=a(5),r=Object(s.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("ol",[t("li",[e._v("[117] Observations and Opportunities in Architecting Shared Virtual Memory for Heterogeneous Systems üëç üëç üëç üëç üë¥")]),e._v(" "),t("li",[e._v("[68] Sheduling Page Table Walks for Irregular GPU Applications")])]),e._v(" "),t("hr"),e._v(" "),t("h1",{attrs:{id:"_1-observations-and-opportunities-in-architecting-shared-virtual-memory-for-heterogeneous-systems"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-observations-and-opportunities-in-architecting-shared-virtual-memory-for-heterogeneous-systems"}},[e._v("#")]),e._v(" 1. Observations and Opportunities in Architecting Shared Virtual Memory for Heterogeneous Systems")]),e._v(" "),t("h2",{attrs:{id:"contributions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#contributions"}},[e._v("#")]),e._v(" Contributions")]),e._v(" "),t("p",[e._v("(1) servicing a TLB  miss from the GPU can be an order of magnitude slower than  that from the CPU and consequently it is imperative to enable\nmany concurrent TLB misses to hide this larger latency;\n(2) divergence in memory accesses impacts the GPU‚Äôs address translation more than the rest of the memory hierarchy, and research in designing address translation mechanisms tolerant to this effect is imperative;\n(3) page faults from the GPU are considerably slower than that from the CPU and software-hardware  co-design is essential for efficient implementation of page faults from throughput-oriented accelerators like GPUs.")]),e._v(" "),t("h2",{attrs:{id:"background"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#background"}},[e._v("#")]),e._v(" Background")]),e._v(" "),t("p",[e._v("The IOMMU resides in the processor‚Äôs northbridge complex."),t("br"),e._v("\nThe IOMMU can access the same x86-64 page table structures used by processes running on the CPU."),t("br"),e._v("\nThis enables the accelerator to share the same set of page tables (and thus the same virtual address space) as the processes running on the CPU via the IOMMU."),t("br"),e._v("\nA software driver in the OS executing on the CPU manages the IOMMU."),t("br"),e._v("\nThe runtime software, in coordination with the OS driver, sets up the IOMMU to enable accelerators access to the same virtual address spaces of the CPU.")]),e._v(" "),t("h2",{attrs:{id:"address-translation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#address-translation"}},[e._v("#")]),e._v(" Address Translation")]),e._v(" "),t("p",[e._v("The GPU has its own TLB hierarchy that caches recently used address translations."),t("br"),e._v("\nOn a GPU TLB miss, a translation request is sent as an ATS (Address Translation Service [17]) request packet over the PCIe¬Æ-based [27] internal interconnect to the IOMMU."),t("br"),e._v(" "),t("strong",[e._v("This interconnect carries PCIe¬Æ packets but latency and bandwidth are not necessarily constrained by PCIe¬Æ‚Äôs electrical specifications")]),e._v("."),t("br"),e._v("\nThe IOMMU has its own TLB hierarchy which is checked first;"),t("br"),e._v("\non a miss there, a hardware page table walker in the IOMMU checks the page table."),t("br"),e._v("\nATS requests are tagged with a process address space identifier (PASID) and the IOMMU maintains a table that matches PASIDs to page table base physical addresses."),t("br"),e._v("\nOnce the address is successfully translated, the IOMMU sends an ATS response to the GPU."),t("br"),e._v("\nThe protocol and packet formats for ATS requests and responses are part of the PCIe¬Æ standard specification and are the same across all accelerators.")]),e._v(" "),t("p",[e._v("The PCIe¬Æ‚Äôs ATS protocol enables devices (and accelerators) to prefetch translation requests for up to eight contiguous virtual address pages in a single ATS response from the IOMMU."),t("br"),e._v("\nBy default, the GPU in our system allows the prefetch value to the maximum setting of eight.")]),e._v(" "),t("p",[t("strong",[e._v("Comparison with CPUs: In the CPU, per-core Memory management Units (MMUs) are responsible for address translations."),t("br"),e._v("\nIn contrast, the IOMMU services requests from all accelerators."),t("br"),e._v("\nUnlike the CPU‚Äôs MMU, the IOMMU is not tightly integrated with CPU‚Äôs data cache hierarchy."),t("br"),e._v("\nThe data caches may contain the most up-to-date translations but the cached copies cannot be directly accessed by accelerators.")])]),e._v(" "),t("h2",{attrs:{id:"page-fault"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#page-fault"}},[e._v("#")]),e._v(" Page Fault")]),e._v(" "),t("p",[e._v("If the IOMMU‚Äôs page table walker fails to find the desired translation in the page table, it sends an ATS response to the GPU notifying it of this failure."),t("br"),e._v("\nThis in turn corresponds to a page fault."),t("br"),e._v("\nIn response, the GPU sends another request to the IOMMU called a Peripheral Page Request (PPR)."),t("br"),e._v("\nThe IOMMU places this request in a memory-mapped queue and raises an interrupt on the CPU."),t("br"),e._v("\nMultiple PPR requests can be queued before the CPU is interrupted."),t("br"),e._v("\nThe OS must have a suitable IOMMU driver to process this interrupt and the queued PPR requests."),t("br"),e._v("\nIn Linux, while in an interrupt context, the driver pulls PPR requests from the queue and places them in a work-queue for later processing. "),t("br"),e._v("\nPresumably this design decision was made to minimize the time spent executing in an interrupt context, where lower priority interrupts would be disabled. "),t("br"),e._v("\nAt a later time, an OS worker-thread calls back into the driver to process page fault requests in the work-queue."),t("br"),e._v("\nOnce the requests are serviced, the driver notifies the IOMMU."),t("br"),e._v("\nIn turn, the IOMMU notifies the GPU."),t("br"),e._v("\nThe GPU then sends another ATS request to retry the translation for the original faulting address.")]),e._v(" "),t("h2",{attrs:{id:"important-analysis"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#important-analysis"}},[e._v("#")]),e._v(" Important Analysis")]),e._v(" "),t("p",[e._v("We divide the time to handle a GPU page fault into three major parts:"),t("br"),e._v("\n(1) ‚Äúinitialization‚Äù, the latency for the OS driver to read the fault requests from the PPR queue and pre-process it;\n(2) ‚Äúprocessing‚Äù, the latency to find a physical page and update the page table;\n(3) ‚Äúschedule‚Äù, the time between initialization and processing of a page fault request.\nWe observe that only "),t("strong",[e._v("a small fraction of the time is spent in actually processing the work to service a page fault.")]),e._v(" "),t("br"),e._v("\nThe OS‚Äôs scheduling delay introduced by the asynchronous handling of GPU page faults is the primary contributor to the latency.\n"),t("strong",[e._v("This suggests that page faults from the GPU can be handled more efficiently by modifying the OS driver to handle the faults synchronously whenever possible.")])]),e._v(" "),t("h2",{attrs:{id:"concluding-remarks"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#concluding-remarks"}},[e._v("#")]),e._v(" Concluding Remarks")]),e._v(" "),t("p",[e._v("Observations and opportunities:")]),e._v(" "),t("ol",[t("li",[e._v("Latency of servicing a TLB miss is significantly higher on a GPU than on a CPU (~25).")]),e._v(" "),t("li",[e._v("Increasing the number of concurrent page table walks supported by the hardware is key to supporting diverse heterogeneous applications.")]),e._v(" "),t("li",[e._v("Half of the programs we studied suffer performance degradation from GPU address translation overheads.")]),e._v(" "),t("li",[e._v("Larger pages are effective in reducing TLB misses. Heterogeneous software and hardware should enhance support for larger page sizes.")]),e._v(" "),t("li",[e._v("Divergence in memory accesses impacts address translation overhead more than cache and DRAM latency. Research into divergence-tolerant address translation mechanisms for throughput-oriented accelerators is important.")]),e._v(" "),t("li",[e._v("Prefetching address translations can degrade performance for programs with poor locality. Applicationdependent translation prefetching is desirable.")])]),e._v(" "),t("p",[e._v("Observations and opportunities:")]),e._v(" "),t("ol",[t("li",[e._v("The latency to service a page fault from the GPU can be significantly higher than from the CPU.")]),e._v(" "),t("li",[e._v("Enhancements into system software to handle page faults synchronously can reduce this latency.")]),e._v(" "),t("li",[e._v("Software-hardware co-design is needed service a large number of concurrent faults from the GPU/accelerators.")]),e._v(" "),t("li",[e._v("It is imperative to scale CPU performance and resources to scale the GPU page fault servicing.")]),e._v(" "),t("li",[e._v("Future heterogeneous applications can reduce their physical memory footprints through the use of on-demand page faults from the GPU, although current applications may need to be re-written.")])]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/f3b7b7a9-6290-4c1d-abc6-dd1c901d5a13",alt:"image"}})]),e._v(" "),t("hr"),e._v(" "),t("h1",{attrs:{id:"_2-sheduling-page-table-walks-for-irregular-gpu-applications-2018"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-sheduling-page-table-walks-for-irregular-gpu-applications-2018"}},[e._v("#")]),e._v(" 2. Sheduling Page Table Walks for Irregular GPU Applications [2018]")]),e._v(" "),t("ul",[t("li",[e._v("better forward progress is achieved by prioritizing translation requests from the instructions that require less work to service their\naddress translation needs.")]),e._v(" "),t("li",[e._v("batching walk requests originating from the same SIMD instruction could reduce unnecessary stalls.")])]),e._v(" "),t("h2",{attrs:{id:"background-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#background-2"}},[e._v("#")]),e._v(" Background")]),e._v(" "),t("p",[e._v("real hardware demonstrated that such divergent memory accesses can slow down an irregular GPU application by up to 3.7-4√ó due to address translation overheads alone [5]."),t("br"),e._v("\nThe study found that the negative impact of divergence could be greater on address translation than on the caches.")]),e._v(" "),t("p",[e._v("Due to the lack of sufficient spatial locality in such irregular applications, these requests often miss in TLBs, each generating a page table walk request.")]),e._v(" "),t("p",[e._v("we show that the order in which page table walk requests are serviced is also critical.")]),e._v(" "),t("p",[t("em",[e._v("First")]),e._v(", the number of page table walks generated due to the execution of a single SIMD memory instruction can vary widely based on how many distinct pages the instruction accesses and the TLB hits/misses it generates.\na completely divergent SIMD instruction can generate page table walk requests equal to the number of workitems in the wavefront (here, 64)."),t("br"),e._v(" "),t("em",[e._v("Second")]),e._v(", each page walk may itself need anywhere between one to four memory requests to complete."),t("br"),e._v("\nThis happens due to hits/misses in page walk caches (PWCs) that store recently-used upperlevel entries of four-level page tables (d")]),e._v(" "),t("h2",{attrs:{id:"introduction"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[e._v("#")]),e._v(" Introduction")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/506931a6-b757-4ff1-bbbe-025419796e71",alt:"image"}})]),e._v(" "),t("ol",[t("li",[e._v("An address translation request is generated when executing a SIMD memory instruction (load/store).")]),e._v(" "),t("li",[e._v("A coalescer merges multiple requests to the same page (e.g., 4KB) generated by the same SIMD instruction.")]),e._v(" "),t("li",[e._v("The coalesced translation request looks up the GPU‚Äôs L1 TLB and then the GPU‚Äôs shared L2 (if L1 misses).")]),e._v(" "),t("li",[e._v("On a miss in the GPU‚Äôs L2 TLB, the request is sent to the IOMMU.")]),e._v(" "),t("li",[e._v("Upon arrival at the IOMMU, the request looks up the IOMMU‚Äôs TLBs. An IOMMU typically supports multiple independent page table walkers (e.g., 8-16) to concurrently service multiple page table walk requests (TLB misses).")]),e._v(" "),t("li",[e._v("On a miss, the request queues up as a page walk request in the IOMMU buffer.")]),e._v(" "),t("li",[e._v("When an IOMMU‚Äôs page table walker becomes free, it typically selects a pending request from the IOMMU buffer in FCFS order.")]),e._v(" "),t("li",[e._v("The page table walker first performs a PWC "),t("em",[e._v("(page table walk caches)")]),e._v(" lookup and then completes the walk of the page table, generating one to four memory accesses.")]),e._v(" "),t("li",[e._v("On finishing a walk, the desired translation is returned to the TLBs and ultimately to the SIMD unit that requested it.")])]),e._v(" "),t("h2",{attrs:{id:"idea"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#idea"}},[e._v("#")]),e._v(" Idea")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/580b28d0-71f8-428a-852a-514204e070ed",alt:"image"}})]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/56b3c46e-9db9-4b8e-bcf1-7066487b4d51",alt:"image"}})])])}),[],!1,null,null,null);t.default=r.exports}}]);