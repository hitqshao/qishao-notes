(window.webpackJsonp=window.webpackJsonp||[]).push([[52],{463:function(e,a,t){"use strict";t.r(a);var r=t(5),s=Object(r.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("ol",[a("li",[e._v("[530 MICRO] Improving GPU Perfromance via Large Warps and Two-Level Warp Scheduling")]),e._v(" "),a("li",[e._v("[219] Improving GPGPU Resource Utilization Through Alternative Thread Blocking Scheduling")])]),e._v(" "),a("hr"),e._v(" "),a("h1",{attrs:{id:"_1-improving-gpu-perfromance-via-large-warps-and-two-level-warp-scheduling"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-improving-gpu-perfromance-via-large-warps-and-two-level-warp-scheduling"}},[e._v("#")]),e._v(" 1. Improving GPU Perfromance via Large Warps and Two-Level Warp Scheduling")]),e._v(" "),a("h2",{attrs:{id:"main-idea-in-short"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#main-idea-in-short"}},[e._v("#")]),e._v(" Main Idea in Short")]),e._v(" "),a("ol",[a("li",[e._v("Solve issue of branch divergence by managing large wrap and create diverged sub-warp from large warp")]),e._v(" "),a("li",[e._v("Two-level warp scheduling. If all warps are scheduled together, they might get stuck by memory access request at the same time."),a("br"),e._v("\nThus they group 32 warps into 4 fetch groups. Group0 is prioritized first and then following warps.")])]),e._v(" "),a("h2",{attrs:{id:"framework"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#framework"}},[e._v("#")]),e._v(" Framework")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/f926ad58-a0fe-4c56-b529-4292b5ccc0ce",alt:"image"}}),e._v(" "),a("img",{attrs:{src:"https://github.com/user-attachments/assets/b0ccc14d-60e6-4cf8-9d55-a5f05693d351",alt:"image"}})]),e._v(" "),a("h2",{attrs:{id:"misc"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#misc"}},[e._v("#")]),e._v(" MISC")]),e._v(" "),a("h3",{attrs:{id:"branch-divergence"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#branch-divergence"}},[e._v("#")]),e._v(" Branch Divergence")]),e._v(" "),a("p",[e._v("Maintainance of branch divergence is well illustrated in the paper.")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/6cf92e7b-a3db-464f-a151-864a35541b51",alt:"image"}})]),e._v(" "),a("ul",[a("li",[e._v("Since a warp can only have a single active PC at any given time, when branch divergence occurs, one path must be chosen first and the other is pushed on a divergence\nstack associated with the warp so that it can be executed later.")]),e._v(" "),a("li",[e._v("The divergence stack is also used to bring the warp back together once the divergent paths have been executed and all threads have reached a control flow merge (CFM)\npoint.")]),e._v(" "),a("li",[e._v("A divergence stack entry consists of three fields: a re-convergence PC, an active mask, and an execute PC.")])]),e._v(" "),a("h2",{attrs:{id:"core-pipeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#core-pipeline"}},[e._v("#")]),e._v(" Core Pipeline")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/065f1360-ea1f-46b8-b5e2-bdb9e24f8e09",alt:"image"}})]),e._v(" "),a("hr"),e._v(" "),a("h1",{attrs:{id:"_2-improving-gpgpu-resource-utilization-through-alternative-thread-blocking-scheduling"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-improving-gpgpu-resource-utilization-through-alternative-thread-blocking-scheduling"}},[e._v("#")]),e._v(" 2. Improving GPGPU Resource Utilization Through Alternative Thread Blocking Scheduling")]),e._v(" "),a("h2",{attrs:{id:"main-idea-in-short-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#main-idea-in-short-2"}},[e._v("#")]),e._v(" Main Idea in Short")]),e._v(" "),a("p",[e._v("Interaction between thread block scheduler and wrap scheduler for different characteristics of workloads")]),e._v(" "),a("ul",[a("li",[e._v("resource contention")]),e._v(" "),a("li",[e._v("inter-CTA locality")])]),e._v(" "),a("h2",{attrs:{id:"introduction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[e._v("#")]),e._v(" Introduction")]),e._v(" "),a("p",[e._v("Two level of schedulers within a GPGPU:")]),e._v(" "),a("ul",[a("li",[e._v("a warp (or a wavefront) scheduler to determine which warp is executed")]),e._v(" "),a("li",[e._v("a thread block or CTA scheduler to assign CTAs to cores")])]),e._v(" "),a("p",[e._v("By default, the current CTA scheduler in hardware assigns the maximum number of CTAs to each core."),a("br"),e._v("\nThe maximum number of CTAs depends on the resources used by each thread and the upper limit is determined the architecture (e.g., 8 CTAs in the Tesla architecture that we evaluate).")]),e._v(" "),a("p",[e._v("Assigning the maximum number of CTAs does not necessarily result in maximum performance as additional CTAs degrade performance by likely creating resource contention.")]),e._v(" "),a("blockquote",[a("p",[a("em",[e._v("Other's work")]),e._v("\nCache Conscious Wavefront Scheduling (CCWS) [29] proposes a warp scheduler that tracks L1 cache accesses to throttle the number of warps scheduled.\nDynamic CTA scheduling (DYNCTA) [16] attempts to allocate the optimal number of CTAs to each core based on the application characteristics.")])]),e._v(" "),a("h2",{attrs:{id:"two-different-scheduling-cta-policy-for-different-workloads"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#two-different-scheduling-cta-policy-for-different-workloads"}},[e._v("#")]),e._v(" Two Different scheduling CTA policy for different workloads")]),e._v(" "),a("p",[e._v("For workloads where the maximum number of CTAs does not maximize performance, we leverage a greedy warp scheduler [29] to propose a lazy CTA scheduling (LCS) where the maximum number of CTAs allocated to each core is reduced to avoid resource contention and performance degradation.")]),e._v(" "),a("p",[e._v("In addition, to exploit inter-CTA locality, we propose block CTA scheduling (in conjunction with an appropriate block-aware warp scheduling) to improve performance and efficiency.")]),e._v(" "),a("h2",{attrs:{id:"observation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#observation"}},[e._v("#")]),e._v(" Observation")]),e._v(" "),a("ul",[a("li",[e._v("Type I : Increased Performance")]),e._v(" "),a("li",[e._v("Type II : Increased Performance and Saturate")])]),e._v(" "),a("p",[e._v("Contention of L1 and increasing L2 miss rate can leads to degrade performance")]),e._v(" "),a("ul",[a("li",[e._v("Type III : Decreased Performance")]),e._v(" "),a("li",[e._v("Type IV : Increase then Decrease")])]),e._v(" "),a("p",[a("strong",[e._v("Core Activity")])]),e._v(" "),a("ul",[a("li",[a("em",[e._v("IDLE")]),a("br"),e._v("\nThere are no available warps that can be issued. This can occur when there are not sufficient warps (and CTAs) assigned to the core.")]),e._v(" "),a("li",[a("em",[e._v("MEM_STALL")]),e._v(" "),a("br"),e._v("\nMost of the warps in the core are stalled waiting for data reply from memory while other warps have no valid instruction to issue.")]),e._v(" "),a("li",[a("em",[e._v("CORE_STALL")]),e._v(" "),a("br"),e._v("\nThe core pipeline is stalled and no warp can be issued."),a("br"),e._v("\nWhile some of the warps in the core might be stalled waiting for data from memory, other warps are stalled because of core/pipeline resource contention (e.g., lack of MSHR entries).")])]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/a39e1839-f055-49df-baf9-f0bbf1ae2a2c",alt:"image"}})]),e._v(" "),a("h2",{attrs:{id:"method"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#method"}},[e._v("#")]),e._v(" Method")]),e._v(" "),a("p",[e._v("We analyzed the behavior of the CTA scheduler through instrumentation."),a("br"),e._v("\nIn the source code of the workloads, we used the PTX register %smid to determine which SM each CTA was assigned to.\n"),a("img",{attrs:{src:"https://github.com/user-attachments/assets/516c6ff8-0618-44c3-aa01-928af6a746ec",alt:"image"}})]),e._v(" "),a("h2",{attrs:{id:"framework-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#framework-2"}},[e._v("#")]),e._v(" Framework")]),e._v(" "),a("h3",{attrs:{id:""}},[a("a",{staticClass:"header-anchor",attrs:{href:"#"}},[e._v("#")])]),e._v(" "),a("p",[e._v("Lazy CTA scheduling (LCS) that reduces the maximum number of CTAs that can be assigned to each core to improve performance and energy efficiency."),a("br"),e._v("\nBlock CTA scheduling (BCS) where sequential CTA blocks are assigned to the same core to improve inter-CTA cache locality and an appropriate warp scheduler that exploits such locality.\n"),a("img",{attrs:{src:"https://github.com/user-attachments/assets/25f19366-20a8-4f5f-8f31-b78323cdf3a9",alt:"image"}})]),e._v(" "),a("h3",{attrs:{id:"lcs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lcs"}},[e._v("#")]),e._v(" LCS")]),e._v(" "),a("p",[e._v("In comparison, LCS only requires a single measurement during the execution of the first thread block and based on the data collected, the number of thread blocks allocated to the core is adjusted.")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/ddc71e56-eb23-40d9-9357-06d24f48852a",alt:"image"}})]),e._v(" "),a("p",[e._v("It is simple. "),a("br"),e._v("\nDuring the monitor phase, the number of instructions issued (inst) for each thread block x is measured. The monitor phase continues until the first thread block finishes execution.")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/bf3786f0-f606-4cb6-aafc-b4c8a5677370",alt:"image"}})]),e._v(" "),a("p",[e._v("In Figure7 (b), Tnew = floor(10/4) = 3")]),e._v(" "),a("h3",{attrs:{id:"-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#-2"}},[e._v("#")])])])}),[],!1,null,null,null);a.default=s.exports}}]);