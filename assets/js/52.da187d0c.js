(window.webpackJsonp=window.webpackJsonp||[]).push([[52],{465:function(e,a,t){"use strict";t.r(a);var r=t(5),i=Object(r.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("ol",[a("li",[e._v("[530 MICRO] Improving GPU Perfromance via Large Warps and Two-Level Warp Scheduling")]),e._v(" "),a("li",[e._v("[219] Improving GPGPU Resource Utilization Through Alternative Thread Blocking Scheduling")])]),e._v(" "),a("hr"),e._v(" "),a("h1",{attrs:{id:"_1-improving-gpu-perfromance-via-large-warps-and-two-level-warp-scheduling"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-improving-gpu-perfromance-via-large-warps-and-two-level-warp-scheduling"}},[e._v("#")]),e._v(" 1. Improving GPU Perfromance via Large Warps and Two-Level Warp Scheduling")]),e._v(" "),a("h2",{attrs:{id:"main-idea-in-short"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#main-idea-in-short"}},[e._v("#")]),e._v(" Main Idea in Short")]),e._v(" "),a("ol",[a("li",[e._v("Solve issue of branch divergence by managing large wrap and create diverged sub-warp from large warp")]),e._v(" "),a("li",[e._v("Two-level warp scheduling. If all warps are scheduled together, they might get stuck by memory access request at the same time."),a("br"),e._v("\nThus they group 32 warps into 4 fetch groups. Group0 is prioritized first and then following warps.")])]),e._v(" "),a("h2",{attrs:{id:"framework"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#framework"}},[e._v("#")]),e._v(" Framework")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/f926ad58-a0fe-4c56-b529-4292b5ccc0ce",alt:"image"}}),e._v(" "),a("img",{attrs:{src:"https://github.com/user-attachments/assets/b0ccc14d-60e6-4cf8-9d55-a5f05693d351",alt:"image"}})]),e._v(" "),a("h2",{attrs:{id:"misc"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#misc"}},[e._v("#")]),e._v(" MISC")]),e._v(" "),a("h3",{attrs:{id:"branch-divergence"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#branch-divergence"}},[e._v("#")]),e._v(" Branch Divergence")]),e._v(" "),a("p",[e._v("Maintainance of branch divergence is well illustrated in the paper.")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/6cf92e7b-a3db-464f-a151-864a35541b51",alt:"image"}})]),e._v(" "),a("ul",[a("li",[e._v("Since a warp can only have a single active PC at any given time, when branch divergence occurs, one path must be chosen first and the other is pushed on a divergence\nstack associated with the warp so that it can be executed later.")]),e._v(" "),a("li",[e._v("The divergence stack is also used to bring the warp back together once the divergent paths have been executed and all threads have reached a control flow merge (CFM)\npoint.")]),e._v(" "),a("li",[e._v("A divergence stack entry consists of three fields: a re-convergence PC, an active mask, and an execute PC.")])]),e._v(" "),a("h2",{attrs:{id:"core-pipeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#core-pipeline"}},[e._v("#")]),e._v(" Core Pipeline")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/065f1360-ea1f-46b8-b5e2-bdb9e24f8e09",alt:"image"}})]),e._v(" "),a("hr"),e._v(" "),a("h1",{attrs:{id:"_2-improving-gpgpu-resource-utilization-through-alternative-thread-blocking-scheduling"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-improving-gpgpu-resource-utilization-through-alternative-thread-blocking-scheduling"}},[e._v("#")]),e._v(" 2. Improving GPGPU Resource Utilization Through Alternative Thread Blocking Scheduling")]),e._v(" "),a("h2",{attrs:{id:"main-idea-in-short-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#main-idea-in-short-2"}},[e._v("#")]),e._v(" Main Idea in Short")]),e._v(" "),a("h2",{attrs:{id:"introduction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[e._v("#")]),e._v(" Introduction")]),e._v(" "),a("p",[e._v("Two level of schedulers within a GPGPU:")]),e._v(" "),a("ul",[a("li",[e._v("a warp (or a wavefront) scheduler to determine which warp is executed")]),e._v(" "),a("li",[e._v("a thread block or CTA scheduler to assign CTAs to cores")])]),e._v(" "),a("p",[e._v("By default, the current CTA scheduler in hardware assigns the maximum number of CTAs to each core."),a("br"),e._v("\nThe maximum number of CTAs depends on the resources used by each thread and the upper limit is determined the architecture (e.g., 8 CTAs in the Tesla architecture that we evaluate).")]),e._v(" "),a("p",[e._v("Assigning the maximum number of CTAs does not necessarily result in maximum performance as additional CTAs degrade performance by likely creating resource contention.")]),e._v(" "),a("blockquote",[a("p",[a("em",[e._v("Other's work")]),e._v("\nCache Conscious Wavefront Scheduling (CCWS) [29] proposes a warp scheduler that tracks L1 cache accesses to throttle the number of warps scheduled.\nDynamic CTA scheduling (DYNCTA) [16] attempts to allocate the optimal number of CTAs to each core based on the application characteristics.")])]),e._v(" "),a("h2",{attrs:{id:"two-different-scheduling-cta-policy-for-different-workloads"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#two-different-scheduling-cta-policy-for-different-workloads"}},[e._v("#")]),e._v(" Two Different scheduling CTA policy for different workloads")]),e._v(" "),a("p",[e._v("For workloads where the maximum number of CTAs does not maximize performance, we leverage a greedy warp scheduler [29] to propose a lazy CTA scheduling (LCS) where the maximum number of CTAs allocated to each core is reduced to avoid resource contention and performance degradation.")]),e._v(" "),a("p",[e._v("In addition, to exploit inter-CTA locality, we propose block CTA scheduling (in conjunction with an appropriate block-aware warp scheduling) to improve performance and efficiency.")])])}),[],!1,null,null,null);a.default=i.exports}}]);