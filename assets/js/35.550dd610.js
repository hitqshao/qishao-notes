(window.webpackJsonp=window.webpackJsonp||[]).push([[35],{445:function(e,t,a){"use strict";a.r(t);var r=a(5),i=Object(r.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("ol",[t("li",[e._v("A survey of architectural approaches for improving GPGPU performance, programmability and heterogeneity")])]),e._v(" "),t("hr"),e._v(" "),t("h1",{attrs:{id:"_1-a-survey-of-architectural-approaches-for-improving-gpgpu-performance-programmability-and-heterogeneity"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-a-survey-of-architectural-approaches-for-improving-gpgpu-performance-programmability-and-heterogeneity"}},[e._v("#")]),e._v(" 1. A survey of architectural approaches for improving GPGPU performance, programmability and heterogeneity")]),e._v(" "),t("p",[e._v("Four major improvement")]),e._v(" "),t("ul",[t("li",[e._v("mitigating the impact of control flow divergence")]),e._v(" "),t("li",[e._v("alleviating resource contention and efficient utilization of memory bandwidth across the entire memory hierarchy, including caches, interconnection and main\nmemory")]),e._v(" "),t("li",[e._v("increasing the available parallelism and concurrency")]),e._v(" "),t("li",[e._v("improving pipeline execution and exploiting scalarization opportunities.")])]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/d9c6b47b-d469-4154-9dc5-b0b0f4168d70",alt:"image"}})]),e._v(" "),t("h2",{attrs:{id:"control-flow-divergence"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#control-flow-divergence"}},[e._v("#")]),e._v(" "),t("strong",[e._v("Control flow divergence")])]),e._v(" "),t("ol",[t("li",[e._v("First, GPUs employ PDOM stack-based mechanism that serializes the execution of divergent paths. This serialization of divergent paths reduces the available thread level parallelism\n(i.e., the number of active warps at a time) which limits the ability of GPUs to hide long memory instruction latency.")]),e._v(" "),t("li",[e._v("Control divergence limits the number of active threads in the running warps. As a result, SIMD execution units are not efficiently utilized when a diverged warp is executed.")]),e._v(" "),t("li",[e._v("Control divergence may also lead memory divergence wherein threads in the same warp access different regions of memory and thus the memory coalescing unit fails to reduce memory requests. Memory divergence causes huge pressure on memory resources and leads long memory latency and performance degradation.")]),e._v(" "),t("li",[e._v("Irregular applications tend to cause workload imbalance in such a way that assigned work (i.e., active threads per CTAs) to some GPU cores are larger than others.")])]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/f9f7621e-ba28-4261-84bf-73b7ba00d9c4",alt:"image"}})]),e._v(" "),t("h3",{attrs:{id:"_1-regrouping-divergent-warps"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-regrouping-divergent-warps"}},[e._v("#")]),e._v(" 1. "),t("strong",[e._v("Regrouping Divergent warps")]),t("br")]),e._v(" "),t("p",[e._v("Instead, DWF dynamically re-forms divergent warps into new non-divergent warps on the fly."),t("br"),e._v("\nMoreover, DWF does not reconverge diverged warp at IPDOM in order to amortize coalesced memory address of converged warps.")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/c19066f6-bbe5-4589-9ae5-58be982e465b",alt:"image"}})]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/bae42a54-ea88-477b-8103-61fd313f03c1",alt:"image"}})]),e._v(" "),t("h3",{attrs:{id:"_2-large-warp-cta-compaction"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-large-warp-cta-compaction"}},[e._v("#")]),e._v(" 2.  "),t("strong",[e._v("Large Warp/CTA compaction")])]),e._v(" "),t("ul",[t("li",[t("p",[e._v("Thread Block Compaction (TBC)"),t("br"),e._v("\nAllows a group of warps, that belong to the same thread block, to share the same PDOM stack."),t("br"),e._v(" "),t("strong",[e._v("However, TBC stalls all warps within a CTA on any potentially divergent branch until all warps reach the branch point.")])]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/0f41fa75-67e0-40e3-9f3b-fe1e55ca9d3e",alt:"image"}})])])]),e._v(" "),t("p",[e._v("The major difference between 1) and TBC is that 1) can only merge threads in a warp when they are ready in a queue. Thus it miss some potentials.")]),e._v(" "),t("p",[e._v("TBC replace per-warp convergence stack with in-threadblock stack.")]),e._v(" "),t("ul",[t("li",[t("p",[e._v("CAPRI"),t("br"),e._v("\nCAPRI dynamically identifies the compaction effectiveness of a branch and only stalls threads that are predicted to benefit from compaction."),t("br")])]),e._v(" "),t("li",[t("p",[e._v("SLP\nproposed SIMD lane permutation (SLP) as an optimization to expand the applicability of compaction in case of conventional compaction technique is ineffective.")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/5c3a5f0d-40c5-4b17-9d73-e73d064fa170",alt:"image"}})])])]),e._v(" "),t("h3",{attrs:{id:"_3-multi-path-execution"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-multi-path-execution"}},[e._v("#")]),e._v(" 3. "),t("strong",[e._v("Multi-path execution")]),t("br")]),e._v(" "),t("ul",[t("li",[e._v("DPS"),t("br"),e._v("\nDual-path Stack"),t("br")]),e._v(" "),t("li",[e._v("Multi-path Execution"),t("br")])]),e._v(" "),t("h3",{attrs:{id:"_4-mimd-like-architecture"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-mimd-like-architecture"}},[e._v("#")]),e._v(" 4. "),t("strong",[e._v("MIMD-like architecture")]),t("br")]),e._v(" "),t("p",[e._v("Rogers et al. [194] observed that regular applications perform better with a wider warp size, whereas divergent applications achieve better performance with a  smaller warp size. "),t("br"),e._v("\nVWS groups sets of these smaller warps together by ganging their execution in the warp scheduler and thus amortizing the energy consumed by fetch, decode, and warp scheduling across more threads.")]),e._v(" "),t("h3",{attrs:{id:"_5-dynamic-kernels-threads"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-dynamic-kernels-threads"}},[e._v("#")]),e._v(" 5. "),t("strong",[e._v("Dynamic kernels/threads")]),e._v(" "),t("br")]),e._v(" "),t("p",[e._v("Related Paper:\n"),t("strong",[e._v("Characterization and Analysis of Dynamic Parallelism in Unstructured GPU Applications.")]),e._v(" [108] "),t("br"),e._v(" "),t("strong",[e._v("Dynamic Thread Block Launch: A Lightweight Execution Mechanism to Support Irregular Applications on GPUs")]),e._v(". [85] "),t("br"),e._v("\nBy wang jing NVIDIA")]),e._v(" "),t("p",[e._v("üëç üëç üëç\n"),t("strong",[e._v("These two paper has very thorough explanation of how kernels are launched, kernel parameters are gained and how thread create subkernel.")])]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/6e30803e-5aaf-4bad-b626-f301c3487c1f",alt:"image"}})]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/eba31c47-1954-4251-bd72-ab05c1f9ce64",alt:"image"}})]),e._v(" "),t("h2",{attrs:{id:"cuda-enables-dynamic-parallsim-creating-subkernels-from-each-thread"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#cuda-enables-dynamic-parallsim-creating-subkernels-from-each-thread"}},[e._v("#")]),e._v(" CUDA enables dynamic parallsim, creating subkernels from each thread.")]),e._v(" "),t("p",[t("strong",[e._v('Copied from "Characterization"')])]),e._v(" "),t("p",[e._v("When a child kernel is launched, the parameter buffer pointer of the kernel is retrieved through the device runtime API cudaGetParameterBuffer.\nThen the argument values are stored in the parameter buffer and the kernel is launched by calling cudaLaunchDevice.\nAfter that, the device runtime manager appends the child kernels to an execution queue and dispatches the kernel to SMXs according to a certain scheduling policy.\nThe CDP kernel launching overhead comprises of kernel parameter parsing, calling cudaGetParameterBuffer and cudaLaunchDevice, as well as the process that device runtime manager setups,enqueues, manages and dispatches the child kernels.")]),e._v(" "),t("hr"),e._v(" "),t("p",[e._v("however, the huge kernel launching overhead could negate the performance benefit of DFP. The overhead is due to the large number of launched kernels, the associated memory footprint and the low number of running warps per core.The CPU launches GPU kernels by dispatching kernel launching commands. Kernel parameters are passed from CPU to\nGPU at the kernel launching time and stored in the GPU global")]),e._v(" "),t("p",[e._v("Wang et al. [236] proposed new mechanism, called Dynamic Thread Block Launch (DTBL), that employs light-weight thread block rather than heavy-weight device kernel for DFP.")]),e._v(" "),t("hr"),e._v(" "),t("h2",{attrs:{id:"efficient-utilization-of-memory-bandwidth"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#efficient-utilization-of-memory-bandwidth"}},[e._v("#")]),e._v(" "),t("strong",[e._v("Efficient utilization of memory bandwidth")])]),e._v(" "),t("h3",{attrs:{id:"alleviating-cache-thrashing-and-resource-contention"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#alleviating-cache-thrashing-and-resource-contention"}},[e._v("#")]),e._v(" "),t("strong",[e._v("Alleviating cache thrashing, and resource contention")])]),e._v(" "),t("h4",{attrs:{id:"_1-two-level-warp-scheduling"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-two-level-warp-scheduling"}},[e._v("#")]),e._v(" 1. "),t("strong",[e._v("Two-level warp scheduling")])]),e._v(" "),t("ul",[t("li",[e._v("TLRR"),t("br"),e._v(" "),t("img",{attrs:{src:"https://github.com/hitqshao/qishao-notes/assets/23403286/586e0677-70fd-4623-b4ee-beaf001ad3dc",alt:"image"}})])]),e._v(" "),t("p",[e._v("They proposed two-level round-robin warp scheduling (TL-RR), in which the warps are split into fetch groups."),t("br"),e._v("\nTL-RR executes only one fetch group at a time and it schedules warps from the same fetch group in a round-robin fashion."),t("br"),e._v("\nWhen the running warps reach a long latency operation, then the next fetch group is prioritized."),t("br"),e._v("\nThey try to alleviate the issue of threads in all warps "),t("strong",[e._v("arrive the same memory latency instruction at the same time")]),e._v("."),t("br")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("![image](https://github.com/hitqshao/qishao-notes/assets/23403286/6851655b-1a31-45ec-bc79-90cf4b97435d)\n\n![image](https://github.com/hitqshao/qishao-notes/assets/23403286/2ff9dbbb-d756-42e1-b821-bc698417a9a0)\n")])])]),t("ul",[t("li",[e._v("OWL\nOWL augments the TL-RR with CTA-awareness, such that warps are split into groups of CTAs basis rather than warps basis, resulting in increased intra-CTA locality. "),t("br"),e._v("\nOWL gives a group of CTAs higher priority when their data exist at the L1 cache such that they get the opportunity to reuse it, therefore improving L1 hit rates and alleviating cache contention."),t("br")])]),e._v(" "),t("h4",{attrs:{id:"_2-coarse-grained-cta-throttling"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-coarse-grained-cta-throttling"}},[e._v("#")]),e._v(" 2. "),t("strong",[e._v("Coarse-grained CTA throttling")])]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("***DYNCTA** <br>\n- Always executing the maximum possible number of CTAs on a GPU core (i.e., increasing TLP to the maximum) does not always lead to better performance.\n- To alleviate resource contention, they proposed dynamic CTA scheduling mechanism (DYNCTA), which aims to allocate the optimal number of CTAs per GPU core that alleviate memory contention according to an application characteristics. \n- DYNCTA dynamically adjusts over sampling periods the number of active CTAs per GPU core that reduces the memory latency without sacrificing the available TLP.\n***LCS** <br>\nIn contrast to DYNCTA that monitors the workload behavior for the entire kernel execution, LCS leverages GTO scheduler to find the optimal number of thread blocks at the early beginning of kernel execution.\n")])])]),t("h4",{attrs:{id:"_3-fine-grained-warp-throttling"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-fine-grained-warp-throttling"}},[e._v("#")]),e._v(" 3. "),t("strong",[e._v("Fine-grained warp throttling")]),e._v("  ")]),e._v(" "),t("p",[e._v("due to the massive multithreading and the limited capacity of L1 cache, divergent GPGPU applications cause severe cache contention."),t("br")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("CCWS")]),e._v(" "),t("br"),e._v("\nuses a victim tag array, called lost locality detector, to detect warps that have lost locality due to thrashing. These warps are prioritized till they exploit their locality while other warps are descheduled."),t("br")]),e._v(" "),t("li",[t("strong",[e._v("DAWS")]),e._v(" "),t("br"),e._v("\nDAWS is a divergence-based cache footprint predictor to calculate the amount of locality in loops required by each warp. "),t("br"),e._v("\nDAWS uses these predictions to prioritize a group of warps such that the cache footprint of these warps do not exceed the capacity of the L1 cache. "),t("br")])]),e._v(" "),t("h4",{attrs:{id:"_4-fine-grained-warp-throttling"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-fine-grained-warp-throttling"}},[e._v("#")]),e._v(" 4. "),t("strong",[e._v("Fine-grained warp throttling")]),e._v("  ")]),e._v(" "),t("p",[e._v("previous CTA or warp throttling techniques leave memory bandwidth and other chip resources (L2 cache, interconnection and execution units) significantly underutilized.")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("PCAL")]),e._v(" "),t("br"),e._v("\nAt the beginning of kernel execution, PCAL executes an optimal number of active warps, that alleviates thrashing and conflicts, then extra inactive warps are allowed to bypass cache and utilize the other on-chip resources.\nThus, PCAL reduces cache thrashing and effectively utilizes the chip resources that would otherwise go unused by a pure thread throttling approach.")]),e._v(" "),t("li",[t("strong",[e._v("CCA")]),e._v(" "),t("br"),e._v("\nAt the beginning of kernel execution, PCAL executes an optimal number of active warps, that alleviates thrashing and conflicts, then extra inactive warps are allowed to bypass cache and utilize the other on-chip resources. Thus, PCAL reduces cache thrashing and effectively utilizes the chip resources that would otherwise go unused by a pure thread throttling approach.")])])])}),[],!1,null,null,null);t.default=i.exports}}]);