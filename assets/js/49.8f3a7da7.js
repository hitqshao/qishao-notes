(window.webpackJsonp=window.webpackJsonp||[]).push([[49],{460:function(e,a,t){"use strict";t.r(a);var i=t(5),s=Object(i.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("ol",[a("li",[e._v("[90] Dissecting the NVIDIA Volta GPU Architecture via Microbenchmaring")]),e._v(" "),a("li",[e._v("[6] SnakeByte: A TLB Design with Adaptive and Recursive Page Merging in GPUs")])]),e._v(" "),a("hr"),e._v(" "),a("h3",{attrs:{id:"_1-dissecting-the-nvidia-volta-gpu-architecture-via-microbenchmaring"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-dissecting-the-nvidia-volta-gpu-architecture-via-microbenchmaring"}},[e._v("#")]),e._v(" 1. Dissecting the NVIDIA Volta GPU Architecture via Microbenchmaring")]),e._v(" "),a("p",[e._v("On Volta and on all other architectures we examined:")]),e._v(" "),a("ul",[a("li",[e._v("the L1 data cache is indexed by virtual addresses;")]),e._v(" "),a("li",[e._v("the L2 data cache is indexed by physical addresses")])]),e._v(" "),a("h3",{attrs:{id:"_2-snakebyte-a-tlb-design-with-adaptive-and-recursive-page-merging-in-gpus"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-snakebyte-a-tlb-design-with-adaptive-and-recursive-page-merging-in-gpus"}},[e._v("#")]),e._v(" 2. SnakeByte: A TLB Design with Adaptive and Recursive Page Merging in GPUs")]),e._v(" "),a("h4",{attrs:{id:"idea"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#idea"}},[e._v("#")]),e._v(" Idea")]),e._v(" "),a("p",[e._v("SnakeByte allows multiple equal-sized pages coalescing into a page table entry (PTE)."),a("br"),e._v("\nIt records the validity of pages to be merged using a bit vector, and few bits are annexed to indicate the size of merged pages.")]),e._v(" "),a("h4",{attrs:{id:"tlb-ptw-gmmu"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tlb-ptw-gmmu"}},[e._v("#")]),e._v(" TLB & PTW & GMMU")]),e._v(" "),a("p",[e._v("Departing from conventional paging schemes of CPUs that heavily rely on operating systems, hardware-based GPU memory management units (GMMUs) are essential to effectively separate device memory management from host\nCPUs."),a("br"),e._v("\nOtherwise, GPUs require the frequent intervention of OS to handle page table walks (PTWs) and TLB misses, which significantly penalize the GPU performance.")]),e._v(" "),a("p",[e._v("Observations:")]),e._v(" "),a("ul",[a("li",[e._v("GPU workloads demand a large number of TLB entries (e.g., 32K to 256K entries) to handle sizable working sets, but conventional TLBs cannot provide sufficient coverage.")]),e._v(" "),a("li",[e._v("GPU workloads have variable ranges of page contiguity.")])]),e._v(" "),a("p",[a("img",{attrs:{src:"https://github.com/user-attachments/assets/ca8c2089-866b-4c16-a853-3a0f2fc792bc",alt:"image"}})])])}),[],!1,null,null,null);a.default=s.exports}}]);