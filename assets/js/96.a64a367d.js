(window.webpackJsonp=window.webpackJsonp||[]).push([[96],{557:function(e,t,r){"use strict";r.r(t);var a=r(8),o=Object(a.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"cuda-piceces"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#cuda-piceces"}},[e._v("#")]),e._v(" CUDA Piceces")]),e._v(" "),t("h2",{attrs:{id:"bank-conflict-in-shared-memory"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#bank-conflict-in-shared-memory"}},[e._v("#")]),e._v(" bank conflict in shared memory")]),e._v(" "),t("p",[t("a",{attrs:{href:"https://forums.developer.nvidia.com/t/how-to-understand-the-bank-conflict-of-shared-mem/260900",target:"_blank",rel:"noopener noreferrer"}},[e._v("nvidia-forum"),t("OutboundLink")],1)]),e._v(" "),t("p",[e._v("Largest transaction size is 128 bytes(32 thread, 4 byte for each thread).")]),e._v(" "),t("p",[e._v("If each thread access 16 bytes, Thread0 -Thread7 will issue one transaction."),t("br"),e._v("\nThread 8 - Thread15 will issue another transaction.")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://github.com/user-attachments/assets/4e9c1b49-85fc-4804-89af-4dec43146c74",alt:"image"}})]),e._v(" "),t("p",[e._v("In this case, even thread 0 and thread 8 shares the same bank."),t("br"),e._v("\nAs long as they are not in the same transaction, there would be no bank conflict.")]),e._v(" "),t("p",[e._v("Usually we will use tile[TILE_SIZE+1] to avoid bank conflict.")]),e._v(" "),t("h2",{attrs:{id:"open-source-implementation-to-achieve-95-cublas-performance"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#open-source-implementation-to-achieve-95-cublas-performance"}},[e._v("#")]),e._v(" open-source implementation to achieve 95% cuBLAS performance")]),e._v(" "),t("p",[t("a",{attrs:{href:"https://accu.org/journals/overload/32/181/schuetze/",target:"_blank",rel:"noopener noreferrer"}},[e._v("95% cuBLAS"),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{href:"https://github.com/qishao-chalmers/CudaTensorCoreHGEMM",target:"_blank",rel:"noopener noreferrer"}},[e._v("github"),t("OutboundLink")],1)]),e._v(" "),t("p",[e._v("Main Idea:")]),e._v(" "),t("ul",[t("li",[e._v("double buffer")]),e._v(" "),t("li",[e._v("async loading")])]),e._v(" "),t("h2",{attrs:{id:"vectorized-memory-access"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#vectorized-memory-access"}},[e._v("#")]),e._v(" Vectorized Memory Access")]),e._v(" "),t("p",[t("a",{attrs:{href:"https://leimao.github.io/blog/CUDA-Vectorized-Memory-Access/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Vectorized Memory Access- LeiMao"),t("OutboundLink")],1),e._v(" "),t("a",{attrs:{href:"https://developer.nvidia.com/blog/cuda-pro-tip-increase-performance-with-vectorized-memory-access/",target:"_blank",rel:"noopener noreferrer"}},[e._v("CUDA Pro Tip"),t("OutboundLink")],1)]),e._v(" "),t("p",[e._v("This blog conduct experiments on 4byte/8byte/16byte per thread accessing global memory.")]),e._v(" "),t("p",[e._v("16-byte per thread achieves effective memory bandwidth.")]),e._v(" "),t("p",[e._v("This might explain why float4 works.")]),e._v(" "),t("ul",[t("li",[e._v("higher memory bandwidth usage")]),e._v(" "),t("li",[e._v("less instruction")])]),e._v(" "),t("h2",{attrs:{id:"interesting-repos"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#interesting-repos"}},[e._v("#")]),e._v(" Interesting Repos")]),e._v(" "),t("ol",[t("li",[t("a",{attrs:{href:"https://github.com/qishao-chalmers/trove",target:"_blank",rel:"noopener noreferrer"}},[e._v("vector loading of array of structures withs warp primitive"),t("OutboundLink")],1)]),e._v(" "),t("li")])])}),[],!1,null,null,null);t.default=o.exports}}]);